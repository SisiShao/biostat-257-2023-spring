{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biostat/Biomath M257 Homework 7\n",
    "#### Due June 16 @ 11:59PM\n",
    "### author: Sisi Shao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.5\n",
      "Commit 17cfb8e65ea (2023-01-08 06:45 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin21.5.0)\n",
      "  CPU: 10 × Apple M1 Max\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, apple-m1)\n",
      "  Threads: 1 on 8 virtual cores\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw7`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parsers ───────────────── v2.7.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HypergeometricFunctions ─ v0.3.17\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FillArrays ────────────── v1.2.0\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw7/Project.toml`\n",
      " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.3.2\u001b[39m\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.95\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw7/Manifest.toml`\n",
      " \u001b[90m [6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.3.2\u001b[39m\n",
      " \u001b[90m [49dc2e85] \u001b[39m\u001b[92m+ Calculus v0.5.1\u001b[39m\n",
      " \u001b[90m [d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.16.0\u001b[39m\n",
      " \u001b[90m [9e997f8a] \u001b[39m\u001b[92m+ ChangesOfVariables v0.1.7\u001b[39m\n",
      " \u001b[90m [34da2185] \u001b[39m\u001b[92m+ Compat v4.6.1\u001b[39m\n",
      " \u001b[90m [9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.15.0\u001b[39m\n",
      " \u001b[90m [864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.13\u001b[39m\n",
      " \u001b[90m [b429d917] \u001b[39m\u001b[92m+ DensityInterface v0.4.0\u001b[39m\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.95\u001b[39m\n",
      " \u001b[90m [ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.3\u001b[39m\n",
      " \u001b[90m [fa6b7ba4] \u001b[39m\u001b[92m+ DualNumbers v0.6.8\u001b[39m\n",
      " \u001b[90m [1a297f60] \u001b[39m\u001b[92m+ FillArrays v1.2.0\u001b[39m\n",
      " \u001b[90m [34004b35] \u001b[39m\u001b[92m+ HypergeometricFunctions v0.3.17\u001b[39m\n",
      " \u001b[90m [3587e190] \u001b[39m\u001b[92m+ InverseFunctions v0.1.9\u001b[39m\n",
      " \u001b[90m [92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.2\u001b[39m\n",
      " \u001b[90m [692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.4.1\u001b[39m\n",
      " \u001b[90m [682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.24\u001b[39m\n",
      " \u001b[90m [e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.1.0\u001b[39m\n",
      " \u001b[90m [77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.0.2\u001b[39m\n",
      " \u001b[90m [bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.6.0\u001b[39m\n",
      " \u001b[90m [90014a1f] \u001b[39m\u001b[92m+ PDMats v0.11.17\u001b[39m\n",
      " \u001b[90m [69de0a69] \u001b[39m\u001b[92m+ Parsers v2.7.0\u001b[39m\n",
      " \u001b[90m [aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.1.2\u001b[39m\n",
      " \u001b[90m [21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.0\u001b[39m\n",
      " \u001b[90m [1fd47b50] \u001b[39m\u001b[92m+ QuadGK v2.8.2\u001b[39m\n",
      " \u001b[90m [189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      " \u001b[90m [79098fc4] \u001b[39m\u001b[92m+ Rmath v0.7.1\u001b[39m\n",
      " \u001b[90m [a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.1.0\u001b[39m\n",
      " \u001b[90m [276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.2.0\u001b[39m\n",
      " \u001b[90m [82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.6.0\u001b[39m\n",
      " \u001b[90m [2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.0\u001b[39m\n",
      " \u001b[90m [4c63d2b9] \u001b[39m\u001b[92m+ StatsFuns v1.3.0\u001b[39m\n",
      " \u001b[90m [efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.5+0\u001b[39m\n",
      " \u001b[90m [f50d1b31] \u001b[39m\u001b[92m+ Rmath_jll v0.4.0+0\u001b[39m\n",
      " \u001b[90m [0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.1\u001b[39m\n",
      " \u001b[90m [56f22d72] \u001b[39m\u001b[92m+ Artifacts\u001b[39m\n",
      " \u001b[90m [2a0f44e3] \u001b[39m\u001b[92m+ Base64\u001b[39m\n",
      " \u001b[90m [ade2ca70] \u001b[39m\u001b[92m+ Dates\u001b[39m\n",
      " \u001b[90m [f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      " \u001b[90m [7b1f6079] \u001b[39m\u001b[92m+ FileWatching\u001b[39m\n",
      " \u001b[90m [b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils\u001b[39m\n",
      " \u001b[90m [b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.3\u001b[39m\n",
      " \u001b[90m [76f85450] \u001b[39m\u001b[92m+ LibGit2\u001b[39m\n",
      " \u001b[90m [8f399da3] \u001b[39m\u001b[92m+ Libdl\u001b[39m\n",
      " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
      " \u001b[90m [56ddb016] \u001b[39m\u001b[92m+ Logging\u001b[39m\n",
      " \u001b[90m [d6f4376e] \u001b[39m\u001b[92m+ Markdown\u001b[39m\n",
      " \u001b[90m [a63ad114] \u001b[39m\u001b[92m+ Mmap\u001b[39m\n",
      " \u001b[90m [ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      " \u001b[90m [44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.8.0\u001b[39m\n",
      " \u001b[90m [de0858da] \u001b[39m\u001b[92m+ Printf\u001b[39m\n",
      " \u001b[90m [9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
      " \u001b[90m [3fa0cd96] \u001b[39m\u001b[92m+ REPL\u001b[39m\n",
      " \u001b[90m [9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
      " \u001b[90m [ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      " \u001b[90m [9e88b42a] \u001b[39m\u001b[92m+ Serialization\u001b[39m\n",
      " \u001b[90m [6462fe0b] \u001b[39m\u001b[92m+ Sockets\u001b[39m\n",
      " \u001b[90m [2f01184e] \u001b[39m\u001b[92m+ SparseArrays\u001b[39m\n",
      " \u001b[90m [10745b16] \u001b[39m\u001b[92m+ Statistics\u001b[39m\n",
      " \u001b[90m [4607b0f0] \u001b[39m\u001b[92m+ SuiteSparse\u001b[39m\n",
      " \u001b[90m [fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.0\u001b[39m\n",
      " \u001b[90m [a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.1\u001b[39m\n",
      " \u001b[90m [8dfed614] \u001b[39m\u001b[92m+ Test\u001b[39m\n",
      " \u001b[90m [cf7118a7] \u001b[39m\u001b[92m+ UUIDs\u001b[39m\n",
      " \u001b[90m [4ec0a83e] \u001b[39m\u001b[92m+ Unicode\u001b[39m\n",
      " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.0.1+0\u001b[39m\n",
      " \u001b[90m [deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v7.84.0+0\u001b[39m\n",
      " \u001b[90m [29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.10.2+0\u001b[39m\n",
      " \u001b[90m [c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.0+0\u001b[39m\n",
      " \u001b[90m [14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2022.2.1\u001b[39m\n",
      " \u001b[90m [4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.20+0\u001b[39m\n",
      " \u001b[90m [05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.1+0\u001b[39m\n",
      " \u001b[90m [83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.12+3\u001b[39m\n",
      " \u001b[90m [8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.1.1+0\u001b[39m\n",
      " \u001b[90m [8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.48.0+0\u001b[39m\n",
      " \u001b[90m [3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+0\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw7/Project.toml`\n",
      " \u001b[90m [6e4b80f9] \u001b[39mBenchmarkTools v1.3.2\n",
      " \u001b[90m [31c24e10] \u001b[39mDistributions v0.25.95\n",
      " \u001b[90m [37e2e46d] \u001b[39mLinearAlgebra\n",
      " \u001b[90m [9a3f8284] \u001b[39mRandom\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we continue with the linear mixed effects model (LMM)\n",
    "$$\n",
    "    \\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma}_i + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where   \n",
    "- $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,  \n",
    "- $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effects predictor matrix of $i$-th individual,  \n",
    "- $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effects predictor matrix of $i$-th individual,  \n",
    "- $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$,  \n",
    "- $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and  \n",
    "- $\\boldsymbol{\\gamma}_i \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$.\n",
    "\n",
    "The log-likelihood of the $i$-th datum $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$ is \n",
    "$$\n",
    "    \\ell_i(\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma_0^2) = - \\frac{n_i}{2} \\log (2\\pi) - \\frac{1}{2} \\log \\det \\boldsymbol{\\Omega}_i - \\frac{1}{2} (\\mathbf{y} - \\mathbf{X}_i \\boldsymbol{\\beta})^T \\boldsymbol{\\Omega}_i^{-1} (\\mathbf{y} - \\mathbf{X}_i \\boldsymbol{\\beta}),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "    \\boldsymbol{\\Omega}_i = \\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i \\boldsymbol{\\Sigma} \\mathbf{Z}_i^T.\n",
    "$$\n",
    "Given $m$ independent data points $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$, $i=1,\\ldots,m$, we seek the maximum likelihood estimate (MLE) by maximizing the log-likelihood\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma_0^2) = \\sum_{i=1}^m \\ell_i(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma_0^2).\n",
    "$$\n",
    "\n",
    "In HW6, we used the nonlinear programming (NLP) approach (Newton type algorithms) for optimization. In this assignment, we derive and implement an expectation-maximization (EM) algorithm for the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n"
     ]
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, Distributions, LinearAlgebra, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (10 pts) Refresher on normal-normal model\n",
    "\n",
    "Assume the conditional distribution\n",
    "$$\n",
    "\\mathbf{y} \\mid \\boldsymbol{\\gamma} \\sim N(\\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z} \\boldsymbol{\\gamma}, \\sigma^2 \\mathbf{I}_n)\n",
    "$$\n",
    "and the prior distribution\n",
    "$$\n",
    "\\boldsymbol{\\gamma} \\sim N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}).\n",
    "$$\n",
    "By the Bayes theorem, the posterior distribution is\n",
    "\\begin{eqnarray*}\n",
    "f(\\boldsymbol{\\gamma} \\mid \\mathbf{y}) &=& \\frac{f(\\mathbf{y} \\mid \\boldsymbol{\\gamma}) \\times f(\\boldsymbol{\\gamma})}{f(\\mathbf{y})}, \\end{eqnarray*}\n",
    "where $f$ denotes corresponding density. \n",
    "\n",
    "Show that the posterior distribution of random effects $\\boldsymbol{\\gamma}$ is a multivariate normal with mean\n",
    "\\begin{eqnarray*}\n",
    "\\mathbb{E} (\\boldsymbol{\\gamma} \\mid \\mathbf{y}) &=& \\sigma^{-2} (\\sigma^{-2} \\mathbf{Z}^T \\mathbf{Z} + \\boldsymbol{\\Sigma}^{-1})^{-1 } \\mathbf{Z}^T (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) \\\\\n",
    "&=& \\boldsymbol{\\Sigma} \\mathbf{Z}^T (\\mathbf{Z} \\boldsymbol{\\Sigma} \\mathbf{Z}^T + \\sigma^2 \\mathbf{I})^{-1} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})\n",
    "\\end{eqnarray*}\n",
    "and covariance\n",
    "\\begin{eqnarray*}\n",
    "\\text{Var} (\\boldsymbol{\\gamma} \\mid \\mathbf{y}) &=& (\\sigma^{-2} \\mathbf{Z}^T \\mathbf{Z} + \\boldsymbol{\\Sigma}^{-1})^{-1} \\\\\n",
    "&=& \\boldsymbol{\\Sigma} - \\boldsymbol{\\Sigma} \\mathbf{Z}^T (\\mathbf{Z} \\boldsymbol{\\Sigma} \\mathbf{Z}^T + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{Z} \\boldsymbol{\\Sigma}.\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1\n",
    "\n",
    "##### Method: conditional multivariate normal distribution\n",
    "\n",
    "Define $W=\\mathbf{y}-\\mathbf{X\\beta}$, then re-write the above as an augmented linear model:\n",
    "\\begin{align}\n",
    "W &=\\mathbf{Z}e_\\gamma +e_W\\\\\n",
    "\\gamma&=e_\\gamma\\\\\n",
    "e_W&\\sim\\mathcal{N}(0,\\sigma^2I)\\\\\n",
    "e_\\gamma&\\sim\\mathcal{N}(0,\\Sigma)\n",
    "\\end{align}\n",
    "\n",
    "Then immediately we have\n",
    "$$\\left[\\begin{matrix}W\\\\\\gamma\\end{matrix}\\right]\\sim\\mathcal{N}\\left(\\left[\\begin{matrix} 0\\\\0\\end{matrix}\\right],\\left[\\begin{matrix}Z\\Sigma Z^T+\\sigma^2I& Z\\Sigma\\\\\\Sigma Z^T &\\Sigma \\end{matrix}\\right]\\right)$$\n",
    "\n",
    "Thus, by conditional multivariate normal formula in *Biostat 200C* and *Biostat 250A*, we have\n",
    "\n",
    "$$\\gamma|W\\sim\\mathcal{N}(\\mu_{\\gamma|W},\\Sigma_{\\gamma|W})$$\n",
    "\n",
    "where\n",
    "\\begin{align}\n",
    "\\mu_{\\gamma|W}&=\\Sigma Z^T\\left(Z\\Sigma Z^T+\\sigma^2I\\right)^{-1}W\\\\\n",
    "\\Sigma_{\\gamma|W}&=\\Sigma-\\Sigma Z^T(Z\\Sigma Z^T+\\sigma^2I)^{-1}Z\\Sigma\n",
    "\\end{align}\n",
    "\n",
    "Subsituting $W$ with $y-X\\beta$ will reproduce Dr. Zhou's solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. (20 pts) Derive EM algorithm\n",
    "\n",
    "1. Write down the complete log-likelihood\n",
    "$$\n",
    "\\sum_{i=1}^m \\log f(\\mathbf{y}_i, \\boldsymbol{\\gamma}_i \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2)\n",
    "$$\n",
    "\n",
    "2. Derive the $Q$ function (E-step).\n",
    "$$\n",
    "Q(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2 \\mid \\boldsymbol{\\beta}^{(t)}, \\boldsymbol{\\Sigma}^{(t)}, \\sigma^{2(t)}).\n",
    "$$\n",
    "\n",
    "3. Derive the EM (or ECM) update of $\\boldsymbol{\\beta}$, $\\boldsymbol{\\Sigma}$, and $\\sigma^2$ (M-step). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2\n",
    "\n",
    "## Sol Q2\n",
    "\n",
    "#### Q2.1\n",
    "\n",
    "- By Q1, the complete likelihood for a single datum is indeed\n",
    "\\begin{align}\n",
    "\\exp\\left(\\mathcal{L}_i(\\beta,\\Sigma,\\sigma^2)\\right)&=\\frac{1}{(2\\pi)^{n_i/2}\\sigma^{n_i}}\\exp\\{-\\frac{1}{2\\sigma^2}\\lVert y_i-X_i\\beta-Z_i\\gamma_i \\lVert_2^2\\}\\times\\frac{1}{(2\\pi)^{q/2}|\\Sigma|^{1/2}}\\exp\\{-\\frac{1}{2}\\gamma_i^T\\Sigma^{-1}\\gamma_i\\}\\\\\n",
    "&=\\frac{1}{(2\\pi)^{\\frac{q+n_i}{2}}(\\sigma^2)^{\\frac{n_i}{2}}|\\Sigma|^{\\frac{1}{2}}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\left(\\lVert y_i-X_i\\beta-Z_i\\gamma_i \\lVert_2^2\\ +\\ \\sigma^2\\gamma_i^T\\Sigma^{-1}\\gamma_i\\right)\\right\\}\n",
    "\\end{align}\n",
    "\n",
    "Hence, the log-likelihood is\n",
    "\n",
    "$$\\mathcal{L}_i(\\beta,\\Sigma,\\sigma^2)=-\\left[\\frac{q+n_i}{2}\\log2\\pi+\\frac{n_i}{2}\\log\\sigma^2+\\frac{1}{2}\\log|\\Sigma|\\right]-\\frac{1}{2\\sigma^2}\\left[\\lVert y_i-X_i\\beta-Z_i\\gamma_i\\lVert_2^2+\\sigma^2\\gamma_i^T\\Sigma^{-1}\\gamma_i\\right]$$\n",
    "\n",
    "Therefore, the complete log-likelihood for the whole dataset is \n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\beta,\\Sigma,\\sigma^2)&=\\sum_{i=1}^m\\mathcal{L}_i(\\beta,\\Sigma,\\sigma^2)\\\\\n",
    "&=-\\left[\\frac{mq+n}{2}\\log2\\pi+\\frac{n}{2}\\log\\sigma^2+\\frac{m}{2}\\log|\\Sigma|\\right] - \\frac{1}{2\\sigma^2}\\left[\\sum_{i=1}^m\\lVert y_i-X_i\\beta-Z_i\\gamma_i\\lVert_2^2+\\sigma^2\\sum_{i=1}^m\\gamma_i^T\\Sigma^{-1}\\gamma_i\\right]\n",
    "\\end{align}\n",
    "\n",
    "#### Q2.2\n",
    "First, note that\n",
    "$$\\gamma_i^TZ_i^TZ_i\\gamma_i=\\text{Tr}(\\gamma_i\\gamma_i^TZ_i^TZ_i)$$\n",
    "$$\\gamma_i^T\\Sigma^{-1}\\gamma_i=\\text{Tr}(\\gamma_i\\gamma_i^T\\Sigma^{-1})$$\n",
    "\n",
    "Let $w_i=y_i-X_i\\beta^{(t)}$, then by Q1, we know that the first and second **geometric moments** are\n",
    "\n",
    "\\begin{align}\n",
    "\\mu_{1}^{i}=\\mathbb{E}\\left(\\gamma_i\\mid \\boldsymbol{\\beta}^{(t)}, \\boldsymbol{\\Sigma}^{(t)}, \\sigma^{2(t)}\\right)&=\\sigma^{-2(t)}\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}Z_i^Tw_i\\\\\n",
    "\\mu_{2}^{i}=\\mathbb{E}\\left(\\gamma_i\\gamma_i^T\\mid \\boldsymbol{\\beta}^{(t)}, \\boldsymbol{\\Sigma}^{(t)}, \\sigma^{2(t)}\\right)&=\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}+\\sigma^{-4(t)}\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}Z_i^Tw_iw_i^TZ_i\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}\n",
    "\\end{align}\n",
    "\n",
    "Hence, the $\\mathcal{Q}$ function is\n",
    "\n",
    "$$\\mathcal{Q}=C-\\frac{n}{2}\\log\\sigma^2-\\frac{m}{2}\\log|\\Sigma|+\\frac{1}{2\\sigma^2}\\left[\\sum_{i=1}^m\\lVert w_i\\lVert_2^2+\\sigma^2\\sum_{i=1}^m\\text{Tr}\\left(\\mu_2^i \\left(\\frac{Z_i^TZ_i}{\\sigma^2}+\\Sigma^{-1}\\right)\\right)-2\\sum_{i=1}^mw_i^TZ_i\\mu_1^i\\right]$$\n",
    "\n",
    "where $C$ is a constant independent of parameters.\n",
    "\n",
    "#### Q2.3\n",
    "\n",
    "Take derivatives w.r.t. all parameters and set them to 0,\n",
    "\n",
    "\\begin{align}\n",
    "\\widehat{\\sigma^2}^{(t+1)}&=\\frac{1}{n}\\sum_{i=1}^m\\left[\\lVert\\widehat{w}_i\\lVert_2^2+\\text{Tr}(\\mu_2^iZ_i^TZ_i)-2w_i^TZ_i\\mu_1^i\\right]\\\\\n",
    "\\widehat{\\beta}^{(t+1)}\n",
    "&=\\left(\\sum_{i=1}^mX_i^TX_i\\right)^{-1}\\left(\\sum_{i=1}^mX_i^T(y_i-Z_i\\mathbf{\\mu}_1^{i})\\right)\\\\\n",
    "\\widehat{\\Sigma}^{(t+1)}&=\\frac{1}{m}\\left(\\sum_{i=1}^m\\mu_2^i\\right)\n",
    "\\end{align}\n",
    "\n",
    "This is by [216 notes](https://ucla-biostat216-2019fall.github.io/slides/16-matrixcalc/16-matrixcalc.html) for deriving derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. (20 pts) Objective of a single datum\n",
    "\n",
    "We modify the code from HW6 to evaluate the objective, the conditional mean of $\\boldsymbol{\\gamma}$, and the conditional variance of $\\boldsymbol{\\gamma}$. Start-up code is provided below. You do _not_ have to use this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # posterior mean and variance of random effects γ\n",
    "    μγ         :: Vector{T} # posterior mean of random effects\n",
    "    νγ         :: Matrix{T} # posterior variance of random effects\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    rtr        :: Vector{T}\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    ztr        :: Vector{T}\n",
    "    ztzu       :: Vector{T}\n",
    "    ltztr      :: Vector{T}\n",
    "    xtr        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    ltztzl     :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "    storage_qq3:: Matrix{T}\n",
    "    storage_I  :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "    y::Vector{T}, \n",
    "    X::Matrix{T}, \n",
    "    Z::Matrix{T}) where T <: AbstractFloat\n",
    "    n, p, q = size(X, 1), size(X, 2), size(Z, 2)\n",
    "    μγ         = Vector{T}(undef, q)\n",
    "    νγ         = Matrix{T}(undef, q, q)\n",
    "    yty        = abs2(norm(y))\n",
    "    rtr        = Vector{T}(undef, 1)\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y\n",
    "    ztr        = similar(zty)\n",
    "    ztzu       = Vector{T}(undef, q)\n",
    "    ltztr      = similar(zty)\n",
    "    xtr        = Vector{T}(undef, p)\n",
    "    storage_p  = similar(xtr)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    ltztzl     = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz)\n",
    "    storage_qq3= similar(ztz)\n",
    "    storage_I  = 1.0 * Matrix(I, q, q)\n",
    "    LmmObs(y, X, Z, μγ, νγ, \n",
    "        yty, rtr, xty, zty, ztr, ztzu, ltztr, xtr,\n",
    "        storage_p, storage_q, \n",
    "        xtx, ztx, ztz, ltztzl, storage_qq, storage_qq2, storage_qq3, storage_I)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, β, Σ, L, σ², updater = false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `β`, `Σ`, \n",
    "and `σ²`. The lower triangular Cholesky factor `L` of `Σ` must be supplied too.\n",
    "The fields `obs.μγ` and `obs.νγ` are overwritten by the posterior mean and \n",
    "posterior variance of random effects. If `updater==true`, fields `obs.ztr`, \n",
    "`obs.xtr`, and `obs.rtr` are updated according to input parameter values. \n",
    "Otherwise, it assumes these three fields are pre-computed. \n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs     :: LmmObs{T}, \n",
    "        β       :: Vector{T}, \n",
    "        Σ       :: Matrix{T},\n",
    "        L       :: Matrix{T},\n",
    "        σ²      :: T,\n",
    "        updater :: Bool = false\n",
    "        ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    σ²inv   = inv(σ²)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################\n",
    "    # form the q-by-q matrix: Lt Zt Z L\n",
    "    copy!(obs.ltztzl, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.ltztzl) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.ltztzl) # O(q^3)        \n",
    "    # form the q-by-q matrix: M = σ² I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ltztzl)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += σ²\n",
    "    end\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # Zt * res\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), copy!(obs.ztr, obs.zty)) # O(pq)\n",
    "    # Lt * (Zt * res)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, copy!(obs.ltztr, obs.ztr))    # O(q^2)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, copy!(obs.storage_q, obs.ltztr)) # O(q^3)\n",
    "    # Xt * res = Xt * y - Xt * X * β\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.xtx, β, T(1), copy!(obs.xtr, obs.xty))\n",
    "    # l2 norm of residual vector\n",
    "    updater && (obs.rtr[1] = obs.yty - dot(obs.xty, β) - dot(obs.xtr, β))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2π) + (n - q) * log(σ²) # constant term\n",
    "    @inbounds for j in 1:q # log det term\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (obs.rtr[1] - qf) * σ²inv \n",
    "    logl /= -2\n",
    "    ######################################\n",
    "    # TODO: Evaluate posterior mean and variance\n",
    "    ######################################    \n",
    "    # TODO\n",
    "    \n",
    "    ## νγ = σ² L(inv(M)inv(Mt))Lt\n",
    "    #obs.storage_qq2 .= L\n",
    "    #BLAS.trsm!('R', 'U', 'N', 'N', T(1.0), obs.storage_qq, obs.storage_qq2)\n",
    "    #mul!(obs.storage_I, obs.storage_qq2, transpose(obs.storage_qq2))\n",
    "    #axpby!(σ², obs.storage_I, 0.0, obs.νγ)\n",
    "    BLAS.trsm!('L', 'L', 'N', 'N', 1.0, L, copy!(obs.νγ, obs.storage_I))\n",
    "    BLAS.trsm!('L', 'L', 'T', 'N', 1.0, L, obs.νγ)\n",
    "    axpby!(σ²inv, obs.ztz, 1.0, obs.νγ)\n",
    "    ### Cholesky of (inv(Σ) + ztz/σ²)\n",
    "    LAPACK.potrf!('L', obs.νγ)\n",
    "    ### Inverse of (inv(Σ) + ztz/σ²)\n",
    "    LAPACK.potri!('L', obs.νγ)\n",
    "    LinearAlgebra.copytri!(obs.νγ, 'L')\n",
    "    \n",
    "    ## inv(σ²) (νγ ztr)\n",
    "    mul!(obs.μγ, obs.νγ, obs.ztr, σ²inv, 0.0)\n",
    "    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/posterior mean/var evaluator here. It's the same test datum as in HW3 and HW6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "Z = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Σ)).L)\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, β, Σ, L, σ², true) = -3256.1793358058376\n",
      "obs.μγ = [0.10608689301332777, -0.2510419060257251, -1.4653979409850368]\n",
      "obs.νγ = [0.0007494356395786613 -1.2183420464422369e-6 -2.1767836829417464e-6; -1.2183420464422369e-6 0.0007542331466357765 2.1553464612468773e-5; -2.1767836829417464e-6 2.1553464612468773e-5 0.0007465271344917232]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, β, Σ, L, σ², true)\n",
    "@show obs.μγ\n",
    "@show obs.νγ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws `AssertionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.μγ - [0.10608689301333621, \n",
    "        -0.25104190602577225, -1.4653979409855415]) < 1e-4\n",
    "@assert norm(obs.νγ - [\n",
    "        0.0007494356395909563 -1.2183420093769967e-6 -2.176783643112221e-6; \n",
    "        -1.2183420282298223e-6 0.0007542331467601107 2.1553464632686345e-5; \n",
    "        -2.1767836636008638e-6 2.1553464641863096e-5 0.0007465271342535443\n",
    "        ]) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 10 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.021 μs\u001b[22m\u001b[39m … \u001b[35m 4.367 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.067 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.071 μs\u001b[22m\u001b[39m ± \u001b[32m56.313 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▅\u001b[39m \u001b[39m \u001b[39m▆\u001b[39m \u001b[39m▇\u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[32m█\u001b[39m\u001b[39m \u001b[39m▆\u001b[39m \u001b[39m \u001b[39m▅\u001b[39m \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m▁\u001b[32m█\u001b[39m\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▂\u001b[39m \u001b[39m▄\n",
       "  1.02 μs\u001b[90m        Histogram: frequency by time\u001b[39m        1.12 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj = @benchmark logl!($obs, $β, $Σ, $L, $σ², true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My median runt time is 800ns. You will get full credit if the median run time is within 10μs. The points you will get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_obj).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for logl!(::LmmObs{Float64}, ::Vector{Float64}, ::Matrix{Float64}, ::Matrix{Float64}, ::Float64)\n",
      "  from logl!(obs::LmmObs{T}, β::Vector{T}, Σ::Matrix{T}, L::Matrix{T}, σ²::T) where T<:AbstractFloat in Main at In[4]:77\n",
      "Static Parameters\n",
      "  T = \u001b[36mFloat64\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(logl!)\u001b[39m\n",
      "  obs\u001b[36m::LmmObs{Float64}\u001b[39m\n",
      "  β\u001b[36m::Vector{Float64}\u001b[39m\n",
      "  Σ\u001b[36m::Matrix{Float64}\u001b[39m\n",
      "  L\u001b[36m::Matrix{Float64}\u001b[39m\n",
      "  σ²\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = (#self#)(obs, β, Σ, L, σ², false)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # check for type stability\n",
    "@code_warntype logl!(obs, β, Σ, L, σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Profile\n",
    "\n",
    "# Profile.clear()\n",
    "# @profile for i in 1:10000; logl!(obs, β, Σ, L, σ²); end\n",
    "# Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. LmmModel type\n",
    "\n",
    "We modify the `LmmModel` type in HW6 to hold all data points, model parameters, and intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmModel"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat}\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    β      :: Vector{T}\n",
    "    Σ      :: Matrix{T}\n",
    "    L      :: Matrix{T}\n",
    "    σ²     :: Vector{T}    \n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty    :: Vector{T}\n",
    "    xtzu   :: Vector{T}\n",
    "    ztu    :: Vector{T}\n",
    "    xtr    :: Vector{T}\n",
    "    ztr2   :: Vector{T}\n",
    "    xtxinv :: Matrix{T}\n",
    "    ztz2   :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    n      = size(obsvec[1].X, 1)\n",
    "    p      = size(obsvec[1].X, 2)\n",
    "    q      = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    β      = Vector{T}(undef, p)\n",
    "    Σ      = Matrix{T}(undef, q, q)\n",
    "    L      = Matrix{T}(undef, q, q)\n",
    "    σ²     = Vector{T}(undef, 1)    \n",
    "    # intermediate arrays\n",
    "    xty    = zeros(T, p)\n",
    "    xtzu   = similar(xty)\n",
    "    ztu    = Vector{T}(undef, n)\n",
    "    xtr    = similar(xty)\n",
    "    ztr2   = Vector{T}(undef, abs2(q))\n",
    "    xtxinv = zeros(T, p, p)\n",
    "    # pre-calculate \\sum_i Xi^T Xi and \\sum_i Xi^T y_i\n",
    "    @inbounds for i in eachindex(obsvec)\n",
    "        obs = obsvec[i]\n",
    "        BLAS.axpy!(T(1), obs.xtx, xtxinv)\n",
    "        BLAS.axpy!(T(1), obs.xty, xty)\n",
    "    end\n",
    "    # invert X'X\n",
    "    LAPACK.potrf!('U', xtxinv)\n",
    "    LAPACK.potri!('U', xtxinv)\n",
    "    LinearAlgebra.copytri!(xtxinv, 'U')\n",
    "    ztz2   = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    LmmModel(obsvec, β, Σ, L, σ², xty, xtzu, ztu, xtr, ztr2, xtxinv, ztz2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Implement EM update\n",
    "\n",
    "Let's write the key function `update_em!` that performs one iteration of EM update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary materials for Q5\n",
    "\n",
    "The EM algorithm is\n",
    "\n",
    "\\begin{align}\n",
    "\\widehat{\\sigma^2}^{(t+1)}&=\\frac{1}{n}\\sum_{i=1}^m\\left[\\lVert\\widehat{w}_i\\lVert_2^2+\\text{Tr}(\\mu_2^iZ_i^TZ_i)-2w_i^TZ_i\\mu_1^i\\right]\\\\\n",
    "\\widehat{\\beta}^{(t+1)}\n",
    "&=\\left(\\sum_{i=1}^mX_i^TX_i\\right)^{-1}\\mathbf{X}^T\\left(\\mathbf{y}-\\mathbf{Z}\\mathbf{\\mu}_1\\right)\\\\\n",
    "&=\\left(\\sum_{i=1}^mX_i^TX_i\\right)^{-1}\\left(\\sum_{i=1}^mX_i^T(y_i-Z_i\\mathbf{\\mu}_1^{i})\\right)\\\\\n",
    "\\widehat{\\Sigma}^{(t+1)}&=\\frac{1}{m}\\left(\\sum_{i=1}^m\\mu_2^i\\right)\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "\\mu_{1}^{i}=\\mathbb{E}\\left(\\gamma_i\\mid \\boldsymbol{\\beta}^{(t)}, \\boldsymbol{\\Sigma}^{(t)}, \\sigma^{2(t)}\\right)&=\\sigma^{-2(t)}\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}Z_i^Tw_i\\\\\n",
    "\\mu_{2}^{i}=\\mathbb{E}\\left(\\gamma_i\\gamma_i^T\\mid \\boldsymbol{\\beta}^{(t)}, \\boldsymbol{\\Sigma}^{(t)}, \\sigma^{2(t)}\\right)&=\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}+\\sigma^{-4(t)}\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}Z_i^Tw_iw_i^TZ_i\\left(\\frac{Z_i^TZ_i}{\\sigma^{2(t)}}+(\\boldsymbol{\\Sigma}^{(t)})^{-1}\\right)^{-1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_em!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_em!(m::LmmModel, updater::Bool = false)\n",
    "\n",
    "Perform one iteration of EM update. It returns the log-likelihood calculated \n",
    "from input `m.β`, `m.Σ`, `m.L`, and `m.σ²`. These fields are then overwritten \n",
    "by the next EM iterate. The fields `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` are updated according to the resultant `m.β`. If `updater==true`, \n",
    "the function first updates `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` according to `m.β`. If `updater==false`, it assumes these fields \n",
    "are pre-computed.\n",
    "\"\"\"\n",
    "function update_em!(m::LmmModel{T}, updater::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    M = length(m.data)\n",
    "    # TODO: update m.β\n",
    "    fill!(m.xtzu, 0.0)\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.β, m.Σ, m.L, m.σ²[1], true)\n",
    "        \n",
    "        mul!(obs.storage_p, transpose(obs.ztx), obs.μγ)\n",
    "        BLAS.axpby!(T(1), obs.storage_p, T(1), m.xtzu)\n",
    "    end\n",
    "    axpby!(1.0, m.xty, -1.0, m.xtzu)\n",
    "    BLAS.gemv!('N', 1.0, m.xtxinv, m.xtzu, 0.0, m.β)\n",
    "    \n",
    "    # TODO: update m.data[i].ztr, m.data[i].xtr, m.data[i].rtr\n",
    "    sum_n = 0.0\n",
    "    fill!(m.σ², 0.0)\n",
    "    fill!(m.Σ, 0.0)\n",
    "    \n",
    "    @inbounds for i in 1:M\n",
    "        obs = m.data[i]\n",
    "        \n",
    "        if updater\n",
    "        # update m.data[i].ztr, m.data[i].xtr, m.data[i].rtr\n",
    "        # Zt * res\n",
    "            BLAS.gemv!('N', T(-1), obs.ztx, m.β, T(1), copy!(obs.ztr, obs.zty))\n",
    "        # Xt * res = Xt * y - Xt * X * β\n",
    "            BLAS.gemv!('N', T(-1), obs.xtx, m.β, T(1), copy!(obs.xtr, obs.xty))\n",
    "        # l2 norm of residual vector\n",
    "            obs.rtr[1] = obs.yty - dot(obs.xty, m.β) - dot(obs.xtr, m.β)\n",
    "        end\n",
    "        \n",
    "        # update m.σ²\n",
    "        sum_n += size(obs.y)[1]\n",
    "        m.σ²[1] += obs.rtr[1]\n",
    "        m.σ²[1] -= 2 * dot(obs.zty, obs.μγ)\n",
    "        m.σ²[1] += 2 * dot(m.β, obs.storage_p)\n",
    "        mul!(obs.storage_qq3, obs.νγ, obs.ztz)\n",
    "        m.σ²[1] += tr(obs.storage_qq3)\n",
    "        BLAS.gemv!('N', T(1), obs.ztz, obs.μγ, T(0), obs.storage_q)\n",
    "        m.σ²[1] += dot(obs.μγ, obs.storage_q)\n",
    "        \n",
    "        # update m.Σ \n",
    "        axpby!(1.0, obs.νγ, 1.0, m.Σ)\n",
    "        BLAS.ger!(1.0, obs.μγ, obs.μγ, m.Σ)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # TODO: update m.σ²\n",
    "    m.σ²[1] /= sum_n\n",
    "    \n",
    "    # update m.L\n",
    "    lmul!(1/M, m.Σ)\n",
    "    LAPACK.potrf!('L', copy!(m.L, m.Σ))\n",
    "    \n",
    "    # return log-likelihood at input parameter values\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. (30 pts) Test data\n",
    "\n",
    "Let's generate a synthetic longitudinal data set (same as HW6) to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "βtrue  = [0.1; 6.5; -3.5; 1.0; 5]\n",
    "σ²true = 1.5\n",
    "σtrue  = sqrt(σ²true)\n",
    "Σtrue  = Matrix(Diagonal([2.0; 1.2; 1.0]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Σtrue)).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * βtrue .+ Z * (Ltrue * randn(q)) .+ σtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "Evaluate log-likelihood and gradient at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj1 = update_em!(lmm, true) = -2.8400684383699736e6\n",
      "lmm.β = [0.10003613673625007, 6.500382871080181, -3.499864634211224, 0.9997124657606651, 4.999230851463544]\n",
      "lmm.Σ = [1.9903882760455252 0.06862095707037451 0.05347290179472647; 0.06862095707037451 1.2813220461216897 -0.0904491332490633; 0.05347290179472647 -0.0904491332490633 0.9435400745724168]\n",
      "lmm.L = [1.4108112120498353 0.06862095707037451 0.05347290179472647; 0.048639361868036066 1.130909482937852 -0.0904491332490633; 0.037902237619045515 -0.08160924927472396 0.9671832429217858]\n",
      "lmm.σ² = [1.4987367279243728]\n",
      "\n",
      "obj2 = update_em!(lmm, false) = -2.8400604605420595e6\n",
      "lmm.β = [0.10007136571174416, 6.500383550631511, -3.4998642980415435, 0.9997119269497639, 4.999229480978786]\n",
      "lmm.Σ = [1.9903775380783657 0.06870107683947124 0.05354351750443938; 0.06870107683947124 1.2814409213711735 -0.09059223997463764; 0.05354351750443938 -0.09059223997463764 0.9434431688085724]\n",
      "lmm.L = [1.410807406444397 0.06870107683947124 0.05354351750443938; 0.04869628308276031 1.1309595896339961 -0.09059223997463764; 0.03795239326066697 -0.0817362364737038 0.9671204538740119]\n",
      "lmm.σ² = [1.4987403307694511]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 1.4987403307694511"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy!(lmm.β, βtrue)\n",
    "copy!(lmm.Σ, Σtrue)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.σ²[1] = σ²true\n",
    "@show obj1 = update_em!(lmm, true)\n",
    "@show lmm.β\n",
    "@show lmm.Σ\n",
    "@show lmm.L\n",
    "@show lmm.σ²\n",
    "println()\n",
    "@show obj2 = update_em!(lmm, false)\n",
    "@show lmm.β\n",
    "@show lmm.Σ\n",
    "@show lmm.L\n",
    "@show lmm.σ²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test correctness. You will loss all 30 points if following code throws `AssertError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(obj1 - (-2.840068438369969e6)) < 1e-4\n",
    "@assert abs(obj2 - (-2.84006046054206e6)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "Test efficiency of EM update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 3688 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.318 ms\u001b[22m\u001b[39m … \u001b[35m 1.518 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.353 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.355 ms\u001b[22m\u001b[39m ± \u001b[32m19.785 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▄\u001b[39m▅\u001b[39m▇\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  1.32 ms\u001b[90m        Histogram: frequency by time\u001b[39m        1.43 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_emupdate = @benchmark update_em!($lmm, true) setup=(\n",
    "    copy!(lmm.β, βtrue);\n",
    "    copy!(lmm.Σ, Σtrue);\n",
    "    copy!(lmm.L, Ltrue);\n",
    "    lmm.σ²[1] = σ²true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My median run time is 1ms. You will get full credit if your median run time is within 10ms. The points you will get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_emupdate).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "You will lose 1 point for each 100 bytes memory allocation. So the points you will get is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_emupdate).memory / 100, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Starting point\n",
    "\n",
    "We use the same least squares estimates as in HW6 as starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kron_axpy!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    init_ls!(m::LmmModel)\n",
    "\n",
    "Initialize parameters of a `LmmModel` object from the least squares estimate. \n",
    "`m.β`, `m.L`, and `m.σ²` are overwritten with the least squares estimates.\n",
    "\"\"\"\n",
    "function init_ls!(m::LmmModel{T}) where T <: AbstractFloat\n",
    "    p, q = size(m.data[1].X, 2), size(m.data[1].Z, 2)\n",
    "    # LS estimate for β\n",
    "    mul!(m.β, m.xtxinv, m.xty)\n",
    "    # LS etimate for σ2 and Σ\n",
    "    rss, ntotal = zero(T), 0\n",
    "    fill!(m.ztz2, 0)\n",
    "    fill!(m.ztr2, 0)    \n",
    "    @inbounds for i in eachindex(m.data)\n",
    "        obs = m.data[i]\n",
    "        ntotal += length(obs.y)\n",
    "        # update Xt * res\n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, m.β, T(1), copy!(obs.xtr, obs.xty))\n",
    "        # rss of i-th individual\n",
    "        rss += obs.yty - dot(obs.xty, m.β) - dot(obs.xtr, m.β)\n",
    "        # update Zi' * res\n",
    "        BLAS.gemv!('N', T(-1), obs.ztx, m.β, T(1), copy!(obs.ztr, obs.zty))\n",
    "        # Zi'Zi ⊗ Zi'Zi\n",
    "        kron_axpy!(obs.ztz, obs.ztz, m.ztz2)\n",
    "        # Zi'res ⊗ Zi'res\n",
    "        kron_axpy!(obs.ztr, obs.ztr, m.ztr2)\n",
    "    end\n",
    "    m.σ²[1] = rss / ntotal\n",
    "    # LS estimate for Σ = LLt\n",
    "    LAPACK.potrf!('U', m.ztz2)\n",
    "    BLAS.trsv!('U', 'T', 'N', m.ztz2, m.ztr2)\n",
    "    BLAS.trsv!('U', 'N', 'N', m.ztz2, m.ztr2)\n",
    "    copyto!(m.Σ, m.ztr2)\n",
    "    copy!(m.L, m.Σ)\n",
    "    LAPACK.potrf!('L', m.L)\n",
    "    for j in 2:q, i in 1:j-1\n",
    "        m.L[i, j] = 0\n",
    "    end\n",
    "    m\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    kron_axpy!(A, X, Y)\n",
    "\n",
    "Overwrite `Y` with `A ⊗ X + Y`. Same as `Y += kron(A, X)` but\n",
    "more memory efficient.\n",
    "\"\"\"\n",
    "function kron_axpy!(\n",
    "        A::AbstractVecOrMat{T},\n",
    "        X::AbstractVecOrMat{T},\n",
    "        Y::AbstractVecOrMat{T}\n",
    "        ) where T <: Real\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    p, q = size(X, 1), size(X, 2)\n",
    "    @assert size(Y, 1) == m * p\n",
    "    @assert size(Y, 2) == n * q\n",
    "    @inbounds for j in 1:n\n",
    "        coffset = (j - 1) * q\n",
    "        for i in 1:m\n",
    "            a = A[i, j]\n",
    "            roffset = (i - 1) * p            \n",
    "            for l in 1:q\n",
    "                r = roffset + 1\n",
    "                c = coffset + l\n",
    "                for k in 1:p                \n",
    "                    Y[r, c] += a * X[k, l]\n",
    "                    r += 1\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    Y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmm.β = [0.18207934611476326, 6.50048070099372, -3.4979107842091595, 1.0011132962297953, 5.0002519857919285]\n",
      "lmm.Σ = [1.9794302836685058 0.07258461003916691 0.05717147035274018; 0.07258461003916693 1.2840385734767714 -0.07707942768978565; 0.05717147035274018 -0.07707942768978565 0.9509885905046899]\n",
      "lmm.L = [1.4069222734993236 0.0 0.0; 0.05159105901325531 1.1319792118703693 0.0; 0.04063584138912111 -0.06994463586493146 0.9718256360134827]\n",
      "lmm.σ² = [5.709004733413668]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 5.709004733413668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ls!(lmm)\n",
    "@show lmm.β\n",
    "@show lmm.Σ\n",
    "@show lmm.L\n",
    "@show lmm.σ²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Estimation by EM\n",
    "\n",
    "We write a function `fit!` that implements the EM algorithm for estimating LMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    fit!(m::LmmModel)\n",
    "\n",
    "Fit an `LmmModel` object by MLE using a EM algorithm. Start point \n",
    "should be provided in `m.β`, `m.σ²`, `m.L`.\n",
    "\"\"\"\n",
    "function fit!(\n",
    "        m       :: LmmModel;\n",
    "        maxiter :: Integer       = 10_000,\n",
    "        ftolrel :: AbstractFloat = 1e-12,\n",
    "        prtfreq :: Integer       = 0\n",
    "    )\n",
    "    obj = update_em!(m, true)\n",
    "    for iter in 0:maxiter\n",
    "        obj_old = obj\n",
    "        # EM update\n",
    "        obj = update_em!(m, false)\n",
    "        # print obj\n",
    "        prtfreq > 0 && rem(iter, prtfreq) == 0 && println(\"iter=$iter, obj=$obj\")\n",
    "        # check monotonicity\n",
    "        obj < obj_old && (@warn \"monotonicity violated\")\n",
    "        # check convergence criterion\n",
    "        (obj - obj_old) < ftolrel * (abs(obj_old) + 1) && break\n",
    "        # warning about non-convergence\n",
    "        iter == maxiter && (@warn \"maximum iterations reached\")\n",
    "    end\n",
    "    m\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. (20 pts) Test drive\n",
    "\n",
    "Now we can run our EM algorithm to compute the MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=0, obj=-2.840068882178379e6\n",
      "iter=1, obj=-2.8400587867554654e6\n",
      "iter=2, obj=-2.840058786725546e6\n",
      "iter=3, obj=-2.8400587867254787e6\n",
      "  0.028271 seconds (57.70 k allocations: 3.161 MiB, 71.43% compilation time)\n",
      "objective value at solution: -2.840058786725409e6\n",
      "\n",
      "solution values:\n",
      "lmm.β = [0.18207855803149936, 6.500383547392576, -3.499864296224195, 0.9997119252318636, 4.999229481214088]\n",
      "lmm.σ² = [1.4987345519183402]\n",
      "lmm.L * transpose(lmm.L) = [1.9910121170848079 0.13511176181337323 0.10338307121955914; 0.13511176181337323 1.2896479966475474 -0.1782018729425176; 0.10338307121955914 -0.1782018729425176 0.94344304716562]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 1.99101    0.135112   0.103383\n",
       " 0.135112   1.28965   -0.178202\n",
       " 0.103383  -0.178202   0.943443"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize from least squares\n",
    "init_ls!(lmm)\n",
    "\n",
    "@time fit!(lmm, prtfreq = 1);\n",
    "\n",
    "println(\"objective value at solution: \", update_em!(lmm)); println()\n",
    "println(\"solution values:\")\n",
    "@show lmm.β\n",
    "@show lmm.σ²\n",
    "@show lmm.L * transpose(lmm.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "You get 10 points if the following code does not throw `AssertError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective at solution should be close enough to the optimal\n",
    "@assert update_em!(lmm) > -2.840059e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "My median run time 5ms. You get 10 points if your median run time is within 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 755 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m6.216 ms\u001b[22m\u001b[39m … \u001b[35m  7.007 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m6.324 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m6.364 ms\u001b[22m\u001b[39m ± \u001b[32m121.267 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▃\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[34m▂\u001b[39m\u001b[39m \u001b[39m▁\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▄\u001b[39m▇\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▄\n",
       "  6.22 ms\u001b[90m         Histogram: frequency by time\u001b[39m        6.81 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_em = @benchmark fit!($lmm) setup = (init_ls!(lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "clamp(1 / (median(bm_em).time / 1e9) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. (10 pts) EM vs Newton type algorithms\n",
    "\n",
    "Contrast EM algorithm to the Newton type algorithms (gradient free, gradient based, using Hessian) in HW6, in terms of the stability, convergence rate (how fast the algorithm is converging),  final objective value, total run time, derivation, and implementation efforts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q10\n",
    "\n",
    "| Items | EM algorithm | Newton-type algorithms |\n",
    "|---|---|---|\n",
    "| stability | Monotonicity (always increasing) |Not guaranteed to be increasing|\n",
    "| Convergence rate | Linear (associated with the eigenvalues of Fisher information matrix) | Fast (e.g., second order for Newton-Raphson) |\n",
    "| Final objective value | -2.840058e6 | -2.83426e6 |\n",
    "| Total run time | 7.007 ms | 0.61 ms |\n",
    "| Derivation| CRAZY and PAINFUL!| Matured technology (according to Dr. Zhou and Dr. Vandenberghe)|\n",
    "|Implementation efforts| Easy (just a few lines)| Extremelly *PAINFUL* to get gradients and Hessian|"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
