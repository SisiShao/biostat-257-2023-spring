{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biostat/Biomath M257 Homework 6\n",
    "###### 'Due June 9 @ 11:59PM'\n",
    "#### author: Sisi Shao (205645669)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.5\n",
      "Commit 17cfb8e65ea (2023-01-08 06:45 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin21.5.0)\n",
      "  CPU: 10 √ó Apple M1 Max\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, apple-m1)\n",
      "  Threads: 1 on 8 virtual cores\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw6`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Downloads/SSS/Courses/Bio257_23Spring/HW/hw6/Project.toml`\n",
      " \u001b[90m [6e4b80f9] \u001b[39mBenchmarkTools v1.3.2\n",
      " \u001b[90m [336ed68f] \u001b[39mCSV v0.10.11\n",
      " \u001b[90m [a93c6f00] \u001b[39mDataFrames v1.5.0\n",
      " \u001b[90m [31c24e10] \u001b[39mDistributions v0.25.95\n",
      " \u001b[90m [b6b21f68] \u001b[39mIpopt v1.4.1\n",
      " \u001b[90m [67920dd8] \u001b[39mKNITRO v0.13.2\n",
      " \u001b[90m [b8f27783] \u001b[39mMathOptInterface v1.17.1\n",
      " \u001b[90m [ff71e718] \u001b[39mMixedModels v4.14.1\n",
      " \u001b[90m [76087f3c] \u001b[39mNLopt v0.6.5\n",
      " \u001b[90m [08abe8d2] \u001b[39mPrettyTables v2.2.4\n",
      " \u001b[90m [6f49c342] \u001b[39mRCall v0.13.15\n",
      " \u001b[90m [8bb1440f] \u001b[39mDelimitedFiles\n",
      " \u001b[90m [37e2e46d] \u001b[39mLinearAlgebra\n",
      " \u001b[90m [9a3f8284] \u001b[39mRandom\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we continue with the linear mixed effects model (LMM) considered in HW3\n",
    "$$\n",
    "    \\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma}_i + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where   \n",
    "- $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,  \n",
    "- $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effects predictor matrix of $i$-th individual,  \n",
    "- $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effects predictor matrix of $i$-th individual,  \n",
    "- $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$,  \n",
    "- $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and  \n",
    "- $\\boldsymbol{\\gamma}_i \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$.\n",
    "\n",
    "The log-likelihood of the $i$-th datum $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$ is \n",
    "$$\n",
    "    \\ell_i(\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma_0^2) = - \\frac{n_i}{2} \\log (2\\pi) - \\frac{1}{2} \\log \\det \\boldsymbol{\\Omega}_i - \\frac{1}{2} (\\mathbf{y} - \\mathbf{X}_i \\boldsymbol{\\beta})^T \\boldsymbol{\\Omega}_i^{-1} (\\mathbf{y} - \\mathbf{X}_i \\boldsymbol{\\beta}),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "    \\boldsymbol{\\Omega}_i = \\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i \\boldsymbol{\\Sigma} \\mathbf{Z}_i^T = \\sigma^2 \\mathbf{I}_{n_i} + \\mathbf{Z}_i \\mathbf{L} \\mathbf{L}^T \\mathbf{Z}_i^T.\n",
    "$$\n",
    "Because the variance component parameter $\\boldsymbol{\\Sigma}$ has to be positive semidefinite. We prefer to use its Cholesky factor $\\mathbf{L}$ as optimization variable. \n",
    "\n",
    "Given $m$ independent data tuples $(\\mathbf{y}_i, \\mathbf{X}_i, \\mathbf{Z}_i)$, $i=1,\\ldots,m$, we seek the maximum likelihood estimate (MLE) by maximizing the log-likelihood\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2) = \\sum_{i=1}^m \\ell_i(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2).\n",
    "$$\n",
    "In this assignment, we use the nonlinear programming (NLP) approach for optimization. In HW7, we will derive an EM (expectation-maximization) algorithm for the same problem. There is also an MM (minorization-maximization) algorithm for the same problem; see [this article](https://doi.org/10.1080/10618600.2018.1529601)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling MixedModels [ff71e718-51f3-5ec2-a782-8ffcbfa3c316]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MathOptInterface"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, CSV, DataFrames, DelimitedFiles, Distributions\n",
    "using Ipopt, LinearAlgebra, MathOptInterface, MixedModels, NLopt\n",
    "using PrettyTables, Random, RCall\n",
    "\n",
    "const MOI = MathOptInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. (Optional, 30 bonus pts) Derivatives\n",
    "\n",
    "NLP optimization solvers expect users to provide at least a function for evaluating objective value. If users can provide further information such as gradient and Hessian, the NLP solvers will be more stable and converge faster. Automatic differentiation tools are becoming more powerful but cannot apply to all problems yet.\n",
    "\n",
    "1. Show that the gradient of $\\ell_i$ is\n",
    "\\begin{eqnarray*}\n",
    "\\nabla_{\\boldsymbol{\\beta}} \\ell_i(\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) &=& \\mathbf{X}_i^T \\boldsymbol{\\Omega}_i^{-1} \\mathbf{r}_i, \\\\\n",
    "\\nabla_{\\sigma^2} \\ell_i(\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) &=& - \\frac{1}{2} \\operatorname{tr} (\\boldsymbol{\\Omega}_i^{-1}) + \\frac{1}{2} \\mathbf{r}_i^T \\boldsymbol{\\Omega}_i^{-2} \\mathbf{r}_i, \\\\\n",
    "\\frac{\\partial}{\\partial \\mathbf{L}} \\ell_i(\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) &=& - \\mathbf{Z}_i^T \\boldsymbol{\\Omega}_i^{-1} \\mathbf{Z}_i \\mathbf{L} + \\mathbf{Z}_i^T \\boldsymbol{\\Omega}_i^{-1} \\mathbf{r}_i \\mathbf{r}_i^T \\boldsymbol{\\Omega}_i^{-1} \\mathbf{Z}_i \\mathbf{L},\n",
    "\\end{eqnarray*}\n",
    "where $\\mathbf{r}_i = \\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}$. \n",
    "\n",
    "2. Derive the observed information matrix and the expected (Fisher) information matrix.\n",
    "\n",
    "If you need a refresher on multivariate calculus, my [Biostat 216 lecture notes](https://ucla-biostat216-2019fall.github.io/slides/16-matrixcalc/16-matrixcalc.html) may be helpful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q1\n",
    "\n",
    "### Sol Q1.1\n",
    "\n",
    "**Step 1**: We cite several results from [Biostat 216 lecture notes](https://ucla-biostat216-2019fall.github.io/slides/16-matrixcalc/16-matrixcalc.html).\n",
    "\n",
    "- (216) $D \\phi(\\mathbf{x})=\\nabla \\phi(\\mathbf{x})^T$; $D \\phi(\\mathbf{X})=\\left(\\text{ vec }\\frac{\\partial\\phi(\\mathbf{x})}{\\partial\\mathbf{X}}\\right)^T$ and the chain rule\n",
    "$$D_{\\mathbf{X}}\\mathbf{Z}=D_\\mathbf{Y}\\mathbf{Z}\\cdot D_\\mathbf{X}\\mathbf{Y}$$\n",
    "- (216) For a scalr-valued matrix function $\\phi(\\mathbf{X})$, we have\n",
    "$$Dùúô(ùêó)=(vec\\frac{‚àÇùúô(ùêó)}{‚àÇùêó})‚Ä≤$$\n",
    "- (216) Let $A(\\alpha)$ be a matrix and its entries are functions of a scalar $\\alpha$, then:\n",
    "\\begin{align}\n",
    "\\frac{d}{d\\alpha}A^{-1}(\\alpha)&=-A^{-1}(\\alpha)\\frac{dA(\\alpha)}{d\\alpha}A^{-1}(\\alpha)\\\\\n",
    "\\frac{d}{d\\alpha}\\log\\det A(\\alpha)&=\\text{Tr}\\left(A^{-1}(\\alpha)\\frac{dA(\\alpha)}{d\\alpha}\\right)\n",
    "\\end{align}\n",
    "- (216) If $\\phi(\\mathbf{X})=\\text{Tr}(\\mathbf{AX}^{-1})$, then\n",
    "$$\\frac{\\partial}{\\partial\\mathbf{X}}\\phi(\\mathbf{X})=-(\\mathbf{X}^{-1}\\mathbf{A}\\mathbf{X}^{-1})^T$$\n",
    "\n",
    "- (216) If $\\phi(\\mathbf{x})=\\mathbf{x}^T\\mathbf{Ax}$, then\n",
    "$$\\frac{\\partial}{\\partial\\mathbf{X}}\\phi(\\mathbf{X})=\\mathbf{x}^T(\\mathbf{A}+\\mathbf{A}^T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** $\\nabla_\\beta$ and $\\nabla_{\\sigma^2}$: Let \n",
    "$$f(\\sigma^2,\\mathbf{L},\\beta)=(\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T \\boldsymbol{\\Omega}_i^{-1} (\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta})=\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-1}\\mathbf{r}_i$$ and $$g(\\sigma^2,\\mathbf{L})=\\log\\det(\\mathbf{\\Omega}_i)$$ then by the chain rule and other results from 216 and 279:\n",
    "$$\\nabla_\\beta f=-2\\mathbf{X}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i$$\n",
    "For $\\sigma^2$, re-write $\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-1}\\mathbf{r}_i=\\text{Tr}\\left(\\mathbf{r}_i\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-1}\\right)$. Then I need to apply the first result:\n",
    "\\begin{align}\n",
    "\\nabla_{\\sigma^2} f&=-\\left(\\text{vec }(\\boldsymbol{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-1})\\right)^T(\\text{vec }\\mathbf{I}_{n_i})\\\\\n",
    "&=-\\text{Tr}\\left[\\boldsymbol{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-1})\\right]\\\\\n",
    "&=-\\mathbf{r}_i^T\\boldsymbol{\\Omega}_i^{-2}\\mathbf{r}_i\n",
    "\\end{align}\n",
    "Similarly,\n",
    "\\begin{align}\n",
    "\\nabla_{\\sigma^2} g&=\\text{Tr}(\\boldsymbol{\\Omega}_i^{-1}\\mathbf{I}_{n_i})=\\text{Tr}(\\boldsymbol{\\Omega}_i^{-1})\n",
    "\\end{align}\n",
    "In conclusion,\n",
    "\\begin{align}\n",
    "\\nabla_{\\sigma^2} \\ell_i&=-\\frac{1}{2}\\nabla_{\\sigma^2} g-\\frac{1}{2}\\nabla_{\\sigma^2} f\\\\\n",
    "&=- \\frac{1}{2} \\operatorname{Tr} (\\boldsymbol{\\Omega}_i^{-1}) + \\frac{1}{2} \\mathbf{r}_i^T \\boldsymbol{\\Omega}_i^{-2} \\mathbf{r}_i\\\\\n",
    "\\nabla_{\\beta} \\ell_i&=-\\frac{1}{2}\\nabla_{\\beta} f\\\\\n",
    "&=\\mathbf{X}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 \n",
    "**Part (a)** $\\nabla_L \\log\\det\\mathbf{\\Omega}^{-1}_i$: For this one, I need an additional result from 216: \n",
    "\n",
    "If $ùêπ(ùêó)=ùêÄùê∫(ùêó)ùêÅùêª(ùêó)ùêÇ$, then\n",
    "$$Dùêπ(ùêó)=(ùêÇ‚Ä≤ùêª(ùêó)‚Ä≤ùêÅ‚Ä≤‚äóùêÄ)Dùê∫(ùêó)+(ùêÇ‚Ä≤‚äóùêÄùê∫(ùêó)ùêÅ)Dùêª(ùêó).$$\n",
    "\n",
    "and another result from [this website](https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf):\n",
    "$$‚àá_X a^T\\mathbf{XX}^Tb = (ab^T + ba^T)\\mathbf{X}$$\n",
    "\n",
    "Plug-in $\\mathbf{X}=\\mathbf{L},\\mathbf{A}=\\mathbf{Z}_i, \\mathbf{B}=\\mathbf{I}_{p}$ and $\\mathbf{C}=\\mathbf{Z}_i^T$ and let \n",
    "$$G(\\mathbf{\\mathbf{L}})=L,\\ H(\\mathbf{\\mathbf{L}})=L^T$$\n",
    "\n",
    "Then we have\n",
    "$$\\frac{\\partial \\mathbf{\\Omega}_i}{\\partial \\mathbf{L}}=\\mathbf{Z}_i\\mathbf{L}\\otimes \\mathbf{Z}_i+\\left(\\mathbf{Z}_i\\otimes\\mathbf{Z}_i\\mathbf{L}\\right)\\mathbf{K}$$\n",
    "\n",
    "where $\\mathbf{K}$ is the $qq\\times qq$ comutation matrix.\n",
    "\n",
    "Next, by **Roth column lemma**,\n",
    "\n",
    "$$\\left(\\text{vec}\\frac{\\partial \\log\\det\\mathbf{\\Omega}_i^{-1}}{\\partial\\mathbf{\\Omega}_i}\\right)^T\\frac{\\partial \\mathbf{\\Omega}_i}{\\partial \\mathbf{L}}=2(\\text{vec }\\mathbf{L}^T\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i)^T$$\n",
    "\n",
    "Re-shape it into matrix form:\n",
    "$$\\frac{\\partial g(\\sigma^2,\\mathbf{L})}{\\partial\\mathbf{L}}=2\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i\\mathbf{L}$$\n",
    "\n",
    "**Part (b)** $\\nabla_Lr_i^T\\mathbf{\\Omega}_i^{-1}r_i$: For this one, all I need are the ***chain rule*** and the following formula.\n",
    "\n",
    "- (216) If $\\phi(\\mathbf{X})=\\text{Tr}(\\mathbf{AX}^{-1})$, then\n",
    "$$\\frac{\\partial}{\\partial \\mathbf{X}}\\phi(\\mathbf{X})=-(\\mathbf{X}^{-1}\\mathbf{A}\\mathbf{X}^{-1})^T$$\n",
    "\n",
    "Note that $$\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i=\\text{Tr}(\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1})$$ \n",
    "Thus,\n",
    "$$\\frac{\\partial}{\\partial \\mathbf{\\Omega}_i}\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i=-\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}$$\n",
    "Hence, again by **Roth column lemma**\n",
    "$$\\left(\\text{vec }\\frac{\\partial}{\\partial \\mathbf{\\Omega}_i}\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\\right)^T\\frac{\\partial \\mathbf{\\Omega}_i}{\\partial \\mathbf{L}}=-2(\\text{vec }\\mathbf{L}^T\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i)^T$$\n",
    "Put it into matrix form:\n",
    "$$\\frac{\\partial \\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i}{\\partial\\mathbf{L}}=-2\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i\\mathbf{L}$$\n",
    "**Part (3)** $\\nabla_L \\ell_i$: Combine part (a) and part (b), I get\n",
    "\\begin{align}\n",
    "\\nabla_\\mathbf{L} \\ell_i&=-\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i\\mathbf{L}+\\mathbf{Z}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{\\Omega}_i^{-1}\\mathbf{Z}_i\\mathbf{L}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q2. (20 pts) Objective and gradient evaluator for a single datum\n",
    "\n",
    "We expand the code from HW3 to evaluate both objective and gradient. I provide my code for HW3 below as a starting point. You do _not_ have to use this code. If your come up faster code, that's even better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q2\n",
    "\n",
    "### Supplementary materials\n",
    "\n",
    "- $\\nabla_{\\beta} \\ell_i$: By SWM formula in HW2, re-write (drop all unnecessary sub-indexes):\n",
    "\\begin{align}\n",
    "\\mathbf{X}^T\\mathbf{\\Omega}^{-1}\\mathbf{r}&=\\frac{1}{\\sigma^2}\\left((X^Ty-X^TX\\beta)-\\underbrace{X^TZL}_{(1)}\\underbrace{U^{-1}U^{-T}L^TZ^Tr}_{(2)}\\right)\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\\begin{align}\n",
    "U&=\\text{chol}(œÉ¬≤I + L^TZ^TZL)\\\\\n",
    "(1)&=\\text{transpose(ztx)}L\\\\\n",
    "(2)&=U\\ \\text{\\\\ storage_q}\n",
    "\\end{align}\n",
    "\n",
    "- $\\nabla_{\\sigma^2} \\ell_i$: The key is to compute the 2 quantities.\n",
    "\n",
    "Again by SWM formula,\n",
    "\\begin{align}\n",
    "\\text{Tr}(\\Omega^{-1})&=\\frac{n}{\\sigma^2}-\\frac{1}{\\sigma^2}\\text{Tr}\\left(\\underbrace{L^TZ^T}_{A^T}ZL(\\sigma^2 I_q+L^TZ^TZL)^{-1}\\right)\\\\\n",
    "&=\\frac{n}{\\sigma^2}-\\frac{1}{\\sigma^2}\\text{Tr}\\left(I_q+\\sigma^2(A^TA)^{-1}\\right)^{-1}\n",
    "\\end{align}\n",
    "Next, by SWM formula again,\n",
    "\\begin{align}\n",
    "\\left(I_q+\\sigma^2(A^TA)^{-1}\\right)^{-1}&=I_q-\\left(\\frac{1}{\\sigma^2} (A^TA) + I_q\\right)^{-1}\n",
    "\\end{align}\n",
    "I get\n",
    "\n",
    "$$\\text{Tr}(\\Omega^{-1})=\\frac{n-q}{\\sigma^2}-\\text{Tr}(\\sigma^2I_q+A^TA)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # arrays for holding gradient\n",
    "    ‚àáŒ≤         :: Vector{T}\n",
    "    ‚àáœÉ¬≤        :: Vector{T}\n",
    "    ‚àáŒ£         :: Matrix{T}    \n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    storage_q2 :: Vector{T}\n",
    "    storage_q3 :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "    storage_Iq :: Matrix{T} \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q    = size(X, 1), size(X, 2), size(Z, 2)    \n",
    "    ‚àáŒ≤         = Vector{T}(undef, p)\n",
    "    ‚àáœÉ¬≤        = Vector{T}(undef, 1)\n",
    "    ‚àáŒ£         = Matrix{T}(undef, q, q)    \n",
    "    yty        = abs2(norm(y))\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y    \n",
    "    storage_p  = Vector{T}(undef, p)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    storage_q2 = Vector{T}(undef, q)\n",
    "    storage_q3 = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz)\n",
    "    storage_Iq = 1.0 * Matrix{T}(I, q, q) \n",
    "    LmmObs(y, X, Z, ‚àáŒ≤, ‚àáœÉ¬≤, ‚àáŒ£, \n",
    "        yty, xty, zty, storage_p, storage_q, storage_q2, storage_q3,\n",
    "        xtx, ztx, ztz, storage_qq, storage_qq2, storage_Iq)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, Œ≤, L, œÉ¬≤, needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `Œ≤`, `L`, \n",
    "and `œÉ¬≤`. If `needgrad==true`, then `obs.‚àáŒ≤`, `obs.‚àáŒ£`, and `obs.œÉ¬≤ are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs      :: LmmObs{T}, \n",
    "        Œ≤        :: Vector{T}, \n",
    "        L        :: Matrix{T}, \n",
    "        œÉ¬≤       :: T,\n",
    "        needgrad :: Bool = true\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################    \n",
    "    # form the q-by-q matrix: M = œÉ¬≤ * I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq) # O(q^3)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += œÉ¬≤\n",
    "    end\n",
    "    # cholesky on M = œÉ¬≤ * I + Lt Zt Z L\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), copy!(obs.storage_q, obs.zty)) # O(pq)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q)    # O(q^2)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q) # O(q^3)\n",
    "    # l2 norm of residual vector\n",
    "    copy!(obs.storage_p, obs.xty)\n",
    "    rtr  = obs.yty +\n",
    "        dot(Œ≤, BLAS.gemv!('N', T(1), obs.xtx, Œ≤, T(-2), obs.storage_p))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2œÄ) + (n - q) * log(œÉ¬≤) # constant term\n",
    "    @inbounds for j in 1:q\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (rtr - qf) / œÉ¬≤ \n",
    "    logl /= -2\n",
    "    ###################\n",
    "    # Evaluate gradient\n",
    "    ###################    \n",
    "    if needgrad\n",
    "        # TODO: fill ‚àáŒ≤, ‚àáL, ‚àáœÉ¬≤ by gradients\n",
    "        # sleep(1e-3) # pretend this step takes 1ms\n",
    "        \n",
    "        # STEP 1:\n",
    "        # ‚àáŒ≤ = X inv(Œ©) r\n",
    "        ## X^TZLU^{-1}storage_q / œÉ¬≤\n",
    "        copy!(obs.storage_q2, obs.storage_q)\n",
    "        BLAS.trsv!('U', 'N', 'N', obs.storage_qq, obs.storage_q2)\n",
    "        copy!(obs.storage_q3, obs.storage_q2)\n",
    "        BLAS.trmv!('L', 'N', 'N', L, obs.storage_q2)\n",
    "        BLAS.gemv!('T', -1/œÉ¬≤, obs.ztx, obs.storage_q2, 0.0, obs.‚àáŒ≤)\n",
    "        ## (X^Ty-X^TXŒ≤) / œÉ¬≤\n",
    "        BLAS.gemv!('N', -1/œÉ¬≤, obs.xtx, Œ≤, 1/œÉ¬≤, copy!(obs.storage_p, obs.xty))\n",
    "        ## Put them together\n",
    "        axpy!(1.0, obs.storage_p, obs.‚àáŒ≤)\n",
    "        \n",
    "        # STEP 2:\n",
    "        # ‚àáœÉ¬≤ = -1/2 * Tr(inv(Œ©)) + 1/2 * r^T (inv(Œ©))^2 r\n",
    "        ## (q-n)/œÉ¬≤ + Tr(inv(œÉ¬≤I+A^TA))/œÉ¬≤\n",
    "        copy!(obs.storage_qq2, obs.storage_Iq)\n",
    "        BLAS.trsm!('L', 'U', 'T', 'N', 1.0, obs.storage_qq, obs.storage_qq2)\n",
    "        obs.‚àáœÉ¬≤[1] = (-n + q) / œÉ¬≤ - sum(abs2, obs.storage_qq2)\n",
    "        ## r^T (inv(Œ©))^2 r\n",
    "        obs.‚àáœÉ¬≤[1] += obs.yty / (œÉ¬≤)^2\n",
    "        copy!(obs.storage_p, obs.xty)\n",
    "        obs.‚àáœÉ¬≤[1] += dot(Œ≤, BLAS.gemv!('N', T(1), obs.xtx, Œ≤, T(-2), obs.storage_p)) / (œÉ¬≤)^2\n",
    "        obs.‚àáœÉ¬≤[1] -= sum(abs2, obs.storage_q3)/œÉ¬≤\n",
    "        obs.‚àáœÉ¬≤[1] -= sum(abs2, obs.storage_q)/(œÉ¬≤)^2\n",
    "        obs.‚àáœÉ¬≤[1] /= (2.0)\n",
    "        \n",
    "        # STEP 3:\n",
    "        # ‚àáL = ‚àíùêô^Tinv(ùõÄ)ùêô+ùêô^Tinv(ùõÄ)ùê´ùê´^Tinv(ùõÄ)ùêô\n",
    "        ## ‚àíùêô^Tinv(ùõÄ)ùêô\n",
    "        copy!(obs.storage_qq2, obs.ztz)\n",
    "        BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "        BLAS.trsm!('L', 'U', 'T', 'N', 1.0, obs.storage_qq, obs.storage_qq2)\n",
    "        mul!(obs.‚àáŒ£, transpose(obs.storage_qq2), obs.storage_qq2)\n",
    "        #rmul!(obs.‚àáŒ£, LowerTriangular(L))\n",
    "        mul!(obs.‚àáŒ£, obs.ztz, I, T(1), T(-1))\n",
    "        rdiv!(obs.‚àáŒ£, -œÉ¬≤)\n",
    "        ## ùêô^Tinv(ùõÄ)ùê´ùê´^Tinv(ùõÄ)ùêô\n",
    "        ### ùêô^Tinv(ùõÄ)ùê´\n",
    "        mul!(obs.storage_q, obs.ztz, obs.storage_q2)\n",
    "        mul!(obs.storage_q, obs.ztx, Œ≤, -1.0, -1.0)\n",
    "        axpy!(1.0, obs.zty, obs.storage_q)\n",
    "        rdiv!(obs.storage_q, œÉ¬≤)\n",
    "        ### Rank 1 update\n",
    "        BLAS.ger!(1.0, obs.storage_q, obs.storage_q, obs.‚àáŒ£)\n",
    "    end    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/gradient evaluator here. First generate the same data set as in [HW3](https://ucla-biostat-257.github.io/2023spring/hw/hw3/hw03.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Œ£)).L)\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, Œ≤, L, œÉ¬≤, true) = -3256.179335805838\n",
      "obs.‚àáŒ≤ = [0.26698108057016157, 41.614183370673814, -34.34664962312672, 36.10898510707504, 27.913948208793883]\n",
      "obs.‚àáœÉ¬≤ = [1.628371513849288]\n",
      "obs.‚àáŒ£ = [-0.9464482950705874 0.057792444809479926 -0.3024412763913972; 0.057792444809479926 -1.0008716491711904 0.28451165571466047; -0.3024412763913972 0.28451165571466047 1.1700409272597256]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, Œ≤, L, œÉ¬≤, true)\n",
    "@show obs.‚àáŒ≤\n",
    "@show obs.‚àáœÉ¬≤\n",
    "@show obs.‚àáŒ£;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws `AssertionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.‚àáŒ≤ - [0.26698108057144054, 41.61418337067327, \n",
    "        -34.34664962312689, 36.10898510707527, 27.913948208793144]) < 1e-4\n",
    "# @assert norm(obs.‚àáŒ£ - \n",
    "#     [-0.9464482950697888 0.057792444809492895 -0.30244127639188767; \n",
    "#         0.057792444809492895 -1.00087164917123 0.2845116557144694; \n",
    "#         -0.30244127639188767 0.2845116557144694 1.170040927259726]) < 1e-4\n",
    "@assert abs(obs.‚àáœÉ¬≤[1] - (1.6283715138412163)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "Benchmark for evaluating objective only. This is what we did in HW3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 172 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m609.012 ns\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m835.756 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m636.140 ns               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m637.109 ns\u001b[22m\u001b[39m ¬± \u001b[32m 12.925 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[34m‚ñá\u001b[39m\u001b[32m‚ñá\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÇ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÑ\n",
       "  609 ns\u001b[90m           Histogram: frequency by time\u001b[39m          680 ns \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark for objective + gradient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 10 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.583 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 3.817 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.629 Œºs              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.630 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m50.510 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÑ\u001b[39m \u001b[39m \u001b[39m‚ñá\u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[34m \u001b[39m\u001b[39m \u001b[39m‚ñÜ\u001b[39m \u001b[39m \u001b[39m‚ñÑ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñá\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[34m‚ñÅ\u001b[39m\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñá\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÉ\n",
       "  1.58 Œºs\u001b[90m        Histogram: frequency by time\u001b[39m        1.66 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_objgrad = @benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My median runt time is 900ns. You will get full credit (10 pts) if the median run time is within 10Œºs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The points you will get are\n",
    "clamp(10 / (median(bm_objgrad).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. LmmModel type\n",
    "\n",
    "We create a `LmmModel` type to hold all data points and model parameters. Log-likelihood/gradient of a `LmmModel` object is simply the sum of log-likelihood/gradient of individual data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat} <: MOI.AbstractNLPEvaluator\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    Œ≤    :: Vector{T}\n",
    "    L    :: Matrix{T}\n",
    "    œÉ¬≤   :: Vector{T}    \n",
    "    # arrays for holding gradient\n",
    "    ‚àáŒ≤   :: Vector{T}\n",
    "    ‚àáœÉ¬≤  :: Vector{T}\n",
    "    ‚àáL   :: Matrix{T}\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty  :: Vector{T}\n",
    "    ztr  :: Vector{T}\n",
    "    ztr2 :: Vector{T}\n",
    "    xtx  :: Matrix{T}\n",
    "    ztz  :: Matrix{T}\n",
    "    ztz2 :: Matrix{T}\n",
    "    Œ£    :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    p    = size(obsvec[1].X, 2)\n",
    "    q    = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    Œ≤    = Vector{T}(undef, p)\n",
    "    L    = Matrix{T}(undef, q, q)\n",
    "    œÉ¬≤   = Vector{T}(undef, 1)    \n",
    "    # gradients\n",
    "    ‚àáŒ≤   = similar(Œ≤)    \n",
    "    ‚àáœÉ¬≤  = similar(œÉ¬≤)\n",
    "    ‚àáL   = similar(L)\n",
    "    # intermediate arrays\n",
    "    xty  = Vector{T}(undef, p)\n",
    "    ztr  = Vector{T}(undef, q)\n",
    "    ztr2 = Vector{T}(undef, abs2(q))\n",
    "    xtx  = Matrix{T}(undef, p, p)\n",
    "    ztz  = Matrix{T}(undef, q, q)\n",
    "    ztz2 = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    Œ£    = Matrix{T}(undef, q, q)\n",
    "    LmmModel(obsvec, Œ≤, L, œÉ¬≤, ‚àáŒ≤, ‚àáœÉ¬≤, ‚àáL, xty, ztr, ztr2, xtx, ztz, ztz2, Œ£)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(m::LmmModel, needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of an LMM model at parameter values `m.Œ≤`, `m.L`, \n",
    "and `m.œÉ¬≤`. If `needgrad==true`, then `m.‚àáŒ≤`, `m.‚àáŒ£`, and `m.œÉ¬≤ are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(m::LmmModel{T}, needgrad::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    if needgrad\n",
    "        fill!(m.‚àáŒ≤ , 0)\n",
    "        fill!(m.‚àáL , 0)\n",
    "        fill!(m.‚àáœÉ¬≤, 0)        \n",
    "    end\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.Œ≤, m.L, m.œÉ¬≤[1], needgrad)\n",
    "        if needgrad\n",
    "            BLAS.axpy!(T(1), obs.‚àáŒ≤, m.‚àáŒ≤)\n",
    "            BLAS.axpy!(T(1), obs.‚àáŒ£, m.‚àáL)\n",
    "            m.‚àáœÉ¬≤[1] += obs.‚àáœÉ¬≤[1]\n",
    "        end\n",
    "    end\n",
    "    # obtain gradient wrt L: m.‚àáL = m.‚àáL * L\n",
    "    if needgrad\n",
    "       # TODO \n",
    "        BLAS.trmm!('R', 'L', 'N', 'N', T(1), m.L, m.‚àáL)\n",
    "    end\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. (20 pts) Test data\n",
    "\n",
    "Let's generate a synthetic longitudinal data set to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "Œ≤true  = [0.1; 6.5; -3.5; 1.0; 5; zeros(p - 5)]\n",
    "œÉ¬≤true = 1.5\n",
    "œÉtrue  = sqrt(œÉ¬≤true)\n",
    "Œ£true  = Matrix(Diagonal([2.0; 1.2; 1.0; zeros(q - 3)]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Œ£true), Val(true), check=false).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * Œ≤true .+ Z * (Ltrue * randn(q)) .+ œÉtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later comparison with other software, we save the data into a text file `lmm_data.csv`. **Do not put this file in Git.** It takes 245.4MB storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(isfile(\"lmm_data.csv\") && filesize(\"lmm_data.csv\") == 245369685) || \n",
    "open(\"lmm_data.csv\", \"w\") do io\n",
    "    p = size(lmm.data[1].X, 2)\n",
    "    q = size(lmm.data[1].Z, 2)\n",
    "    # print header\n",
    "    print(io, \"ID,Y,\")\n",
    "    for j in 1:(p-1)\n",
    "        print(io, \"X\" * string(j) * \",\")\n",
    "    end\n",
    "    for j in 1:(q-1)\n",
    "        print(io, \"Z\" * string(j) * (j < q-1 ? \",\" : \"\\n\"))\n",
    "    end\n",
    "    # print data\n",
    "    for i in eachindex(lmm.data)\n",
    "        obs = lmm.data[i]\n",
    "        for j in 1:length(obs.y)\n",
    "            # id\n",
    "            print(io, i, \",\")\n",
    "            # Y\n",
    "            print(io, obs.y[j], \",\")\n",
    "            # X data\n",
    "            for k in 2:p\n",
    "                print(io, obs.X[j, k], \",\")\n",
    "            end\n",
    "            # Z data\n",
    "            for k in 2:q-1\n",
    "                print(io, obs.Z[j, k], \",\")\n",
    "            end\n",
    "            print(io, obs.Z[j, q], \"\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "Evaluate log-likelihood and gradient of whole data set at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = logl!(lmm, true) = -2.8400684383699736e6\n",
      "lmm.‚àáŒ≤ = [41.06591670741458, 445.75120353967236, 157.01339922458385, -335.09977360732586, -895.6257448385876]\n",
      "lmm.‚àáœÉ¬≤ = [-489.5361730372508]\n",
      "lmm.‚àáL = [-3.398257593541934 31.32103842084881 26.736450897360722; 40.43528672995671 61.86377650462431 -75.37427770754628; 37.81105146876985 -82.56838431216376 -56.4599254275938]\n"
     ]
    }
   ],
   "source": [
    "copy!(lmm.Œ≤, Œ≤true)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.œÉ¬≤[1] = œÉ¬≤true\n",
    "@show obj = logl!(lmm, true)\n",
    "@show lmm.‚àáŒ≤\n",
    "@show lmm.‚àáœÉ¬≤\n",
    "@show lmm.‚àáL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test correctness. You will loss all 20 points if following code throws `AssertError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert abs(obj - (-2.840068438369969e6)) < 1e-4\n",
    "@assert norm(lmm.‚àáŒ≤ - [41.0659167074073, 445.75120353972426, \n",
    "        157.0133992249258, -335.09977360733626, -895.6257448385899]) < 1e-4\n",
    "@assert norm(lmm.‚àáL - [-3.3982575935824837 31.32103842086001 26.73645089732865; \n",
    "        40.43528672997116 61.86377650461202 -75.37427770754684; \n",
    "        37.811051468724486 -82.56838431216435 -56.45992542754974]) < 1e-4\n",
    "@assert abs(lmm.‚àáœÉ¬≤[1] - (-489.5361730382465)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "Test efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 3043 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.596 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 1.890 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.640 ms              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.642 ms\u001b[22m\u001b[39m ¬± \u001b[32m26.558 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÇ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñá\u001b[34m‚ñà\u001b[39m\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÑ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÑ\n",
       "  1.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m        1.74 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_model = @benchmark logl!($lmm, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My median run time is 1.4ms. You will get full credit if your median run time is within 10ms. The points you will get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_model).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n",
    "\n",
    "You will lose 1 point for each 100 bytes memory allocation. So the points you will get is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_model).memory / 100, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. (30 pts) Starting point\n",
    "\n",
    "For numerical optimization, a good starting point is critical. Let's start $\\boldsymbol{\\beta}$ and $\\sigma^2$ from the least sqaures solutions (ignoring intra-individual correlations)\n",
    "\\begin{eqnarray*}\n",
    "\\boldsymbol{\\beta}^{(0)} &=& \\left(\\sum_i \\mathbf{X}_i^T \\mathbf{X}_i\\right)^{-1} \\left(\\sum_i \\mathbf{X}_i^T \\mathbf{y}_i\\right) \\\\\n",
    "\\sigma^{2(0)} &=& \\frac{\\sum_i \\|\\mathbf{r}_i^{(0)}\\|_2^2}{\\sum_i n_i} = \\frac{\\sum_i \\|\\mathbf{y}_i - \\mathbf{X}_i \\boldsymbol{\\beta}^{(0)}\\|_2^2}{\\sum_i n_i}.\n",
    "\\end{eqnarray*}\n",
    "To get a reasonable starting point for $\\boldsymbol{\\Sigma} = \\mathbf{L} \\mathbf{L}^T$, we can minimize the least squares criterion (ignoring the noise variance component)\n",
    "$$\n",
    "    \\text{minimize} \\sum_i \\| \\mathbf{r}_i^{(0)} \\mathbf{r}_i^{(0)T} - \\mathbf{Z}_i \\boldsymbol{\\Sigma} \\mathbf{Z}_i^T \\|_{\\text{F}}^2.\n",
    "$$\n",
    "Derive the minimizer $\\boldsymbol{\\Sigma}^{(0)}$ (10 pts). \n",
    "\n",
    "We implement this start point strategy in the function `init_ls()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol Q5\n",
    "\n",
    "We have\n",
    "\\begin{align}\n",
    "\\lVert \\mathbf{r}\\mathbf{r}^T-\\mathbf{Z\\Sigma Z}^T \\lVert^2_F&=\\text{Tr}\\left[(\\mathbf{r}\\mathbf{r}^T-\\mathbf{Z\\Sigma Z}^T)^T(\\mathbf{r}\\mathbf{r}^T-\\mathbf{Z\\Sigma Z}^T)\\right]\\\\\n",
    "&=\\underbrace{\\text{Tr}(\\mathbf{rr}^T\\mathbf{rr}^T)}_{(1)} - \\underbrace{\\text{Tr}(2\\mathbf{Z}^T\\mathbf{rr}^T\\mathbf{Z\\Sigma })}_{(2)}+\\underbrace{\\text{Tr}(\\mathbf{Z\\Sigma Z}^T\\mathbf{Z\\Sigma Z}^T)}_{(3)}\n",
    "\\end{align}\n",
    "Then \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial (1)}{\\partial\\mathbf{\\Sigma}}&=\\mathbf{O}\\\\\n",
    "\\frac{\\partial (2)}{\\partial\\mathbf{\\Sigma}}&=2\\mathbf{Z}^T\\mathbf{rr}^T\\mathbf{Z} \\\\\n",
    "\\frac{\\partial (3)}{\\partial\\mathbf{\\Sigma}}&=2\\mathbf{Z}^T\\mathbf{Z\\Sigma Z}^T\\mathbf{Z}\n",
    "\\end{align}\n",
    "\n",
    "Set $\\frac{\\partial (1)}{\\partial\\mathbf{\\Sigma}}-\\frac{\\partial (2)}{\\partial\\mathbf{\\Sigma}}+\\frac{\\partial (3)}{\\partial\\mathbf{\\Sigma}}=0$, and then sum over $i=1,2,\\cdots,n$:\n",
    "\n",
    "$$\\sum_{i=1}^n\\mathbf{Z_i}^T\\mathbf{r}_i\\mathbf{r}_i^T\\mathbf{Z}_i=\\sum_{i=1}^n\\mathbf{Z}_i^T\\mathbf{Z}_i\\mathbf{\\Sigma}\\mathbf{Z}_i^T\\mathbf{Z}_i$$\n",
    "\n",
    "Next, by **Roth column lemma** in [Easy Linear Systems](https://ucla-biostat-257-2021spring.github.io/slides/19-easylineq/easylineq.html),\n",
    "$$\\text{vec} \\mathbf{ABC}=(\\mathbf{C}^T\\otimes\\mathbf{A})\\text{vec}\\mathbf{B}$$\n",
    "Thus,\n",
    "\n",
    "$$\\text{vec}\\left(\\sum_{i=1}^n\\mathbf{Z}_i^T\\mathbf{Z}_i\\mathbf{\\Sigma}\\mathbf{Z}_i^T\\mathbf{Z}_i\\right)\n",
    "=\\sum_{i=1}^n\\left(\\mathbf{Z}_i^T\\mathbf{Z}_i\\otimes\\mathbf{Z}_i^T\\mathbf{Z}_i\\right)\\text{vec}\\mathbf{\\Sigma}=\\sum_{i=1}^n\\left(\\mathbf{Z}_i^T\\mathbf{r}_i\\otimes \\mathbf{Z}_i^T\\mathbf{r}_i\\right)$$\n",
    "\n",
    "Hence, the *initial value of $\\Sigma$* is\n",
    "\n",
    "\\begin{align}\n",
    "\\text{vec}\\mathbf{\\Sigma}^{(0)}=\\left(\\sum_{i=1}^n\\mathbf{Z}_i^T\\mathbf{Z}_i\\otimes\\mathbf{Z}_i^T\\mathbf{Z}_i\\right)^{-1}\\left(\\sum_{i=1}^n\\mathbf{Z}_i^T\\mathbf{r}_i\\otimes \\mathbf{Z}_i^T\\mathbf{r}_i\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_ls!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    init_ls!(m::LmmModel)\n",
    "\n",
    "Initialize parameters of a `LmmModel` object from the least squares estimate. \n",
    "`m.Œ≤`, `m.L`, and `m.œÉ¬≤` are overwritten with the least squares estimates.\n",
    "\"\"\"\n",
    "function init_ls!(m::LmmModel{T}) where T <: AbstractFloat\n",
    "    p, q = size(m.data[1].X, 2), size(m.data[1].Z, 2)\n",
    "    # TODO: fill m.Œ≤, m.L, m.œÉ¬≤ by LS estimates\n",
    "    # sleep(1e-3) # pretend this takes 1ms\n",
    "    n = length(m.data)\n",
    "    \n",
    "    fill!(m.xty, 0.0)\n",
    "    fill!(m.ztr, 0.0)\n",
    "    fill!(m.ztr2, 0.0)\n",
    "    fill!(m.xtx, 0.0)\n",
    "    fill!(m.ztz2, 0.0)\n",
    "    fill!(m.Œ≤, 0.0)\n",
    "    fill!(m.L, 0.0)\n",
    "    fill!(m.œÉ¬≤, 0.0)\n",
    "    sum_n = 0\n",
    "    \n",
    "    for i in 1:n\n",
    "        obs = m.data[i]\n",
    "        \n",
    "        # Œ≤\n",
    "        axpy!(T(1), obs.xty, m.xty)\n",
    "        axpy!(T(1), obs.xtx, m.xtx)\n",
    "        m.œÉ¬≤[1] += obs.yty\n",
    "    end\n",
    "    mul!(m.Œ≤, m.xtx \\ I, m.xty)\n",
    "    m.œÉ¬≤[1] += dot(m.Œ≤, BLAS.gemv!('N', T(1), m.xtx, m.Œ≤, T(-2), m.xty))\n",
    "    \n",
    "    for i in 1:n\n",
    "        obs = m.data[i]\n",
    "        \n",
    "        # œÉ¬≤\n",
    "        #copy!(m.xty, obs.xty)\n",
    "        #m.œÉ¬≤[1] += obs.yty + dot(m.Œ≤, BLAS.gemv!('N', T(1), obs.xtx, m.Œ≤, T(-2), m.xty))\n",
    "        sum_n += size(obs.y, 1)\n",
    "        \n",
    "        # ùö∫\n",
    "        ## Ztr \\otimes Ztr\n",
    "        copy!(m.ztr, obs.zty)\n",
    "        BLAS.gemv!('N', T(1), obs.ztx, m.Œ≤, T(-1), m.ztr)\n",
    "        axpy!(T(1), kron(m.ztr, m.ztr), m.ztr2)\n",
    "        ## ZtZ \\otimes ZtZ\n",
    "        axpy!(T(1), kron(obs.ztz, obs.ztz), m.ztz2)\n",
    "    end\n",
    "    \n",
    "    rdiv!(m.œÉ¬≤, sum_n)\n",
    "    LAPACK.posv!('L', m.ztz2, m.ztr2)\n",
    "    m.Œ£ .= reshape(m.ztr2, (q, q))\n",
    "    m.L .= Matrix(cholesky(Symmetric(m.Œ£)).L)\n",
    "    \n",
    "    m\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl!(lmm) = -3.3626049341044296e6\n",
      "lmm.Œ≤ = [0.18207934611476329, 6.500480700993721, -3.4979107842091595, 1.001113296229795, 5.0002519857919285]\n",
      "lmm.œÉ¬≤ = [5.7090047334136225]\n",
      "lmm.L = [1.4069222734993236 0.0 0.0; 0.05159105901325529 1.131979211870369 0.0; 0.04063584138912113 -0.06994463586493148 0.9718256360134827]\n"
     ]
    }
   ],
   "source": [
    "init_ls!(lmm)\n",
    "@show logl!(lmm)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.œÉ¬≤\n",
    "@show lmm.L;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "Your start points should have a log-likelihood larger than -3.3627e6 (10 pts). The points you get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "(logl!(lmm) >  -3.3627e6) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "The start point should be computed quickly. Otherwise there is no point using it as a starting point. My median run time is 175Œºs. You get full credit (10 pts) if the median run time is within 1ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 9195 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m405.125 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m46.213 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m 0.00% ‚Ä¶ 98.50%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m450.584 Œºs              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m542.095 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m 1.312 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m15.77% ¬±  6.76%\n",
       "\n",
       "  \u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÇ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[32m‚ñÖ\u001b[39m\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m \u001b[39m‚ñà\n",
       "  405 Œºs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       684 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.09 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m8010\u001b[39m."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_init = @benchmark init_ls!($lmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "clamp(1 / (median(bm_init).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. NLP via MathOptInterface.jl\n",
    "\n",
    "We define the NLP problem using the modelling tool [MathOptInterface.jl](https://github.com/jump-dev/MathOptInterface.jl). Start-up code is given below. Modify if necessary to accomodate your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    fit!(m::LmmModel, solver=Ipopt.Optimizer())\n",
    "\n",
    "Fit an `LmmModel` object by MLE using a nonlinear programming solver. Start point \n",
    "should be provided in `m.Œ≤`, `m.œÉ¬≤`, `m.L`.\n",
    "\"\"\"\n",
    "function fit!(\n",
    "        m :: LmmModel{T},\n",
    "        solver = Ipopt.Optimizer()\n",
    "    ) where T <: AbstractFloat\n",
    "    p    = size(m.data[1].X, 2)\n",
    "    q    = size(m.data[1].Z, 2)\n",
    "    npar = p + ((q * (q + 1)) >> 1) + 1\n",
    "    # prep the MOI\n",
    "    MOI.empty!(solver)\n",
    "    # set lower bounds and upper bounds of parameters\n",
    "    # q diagonal entries of Cholesky factor L should be >= 0\n",
    "    # œÉ¬≤ should be >= 0\n",
    "    lb   = fill(0.0, q + 1)\n",
    "    ub   = fill(Inf, q + 1)\n",
    "    NLPBlock = MOI.NLPBlockData(MOI.NLPBoundsPair.(lb, ub), m, true)\n",
    "    MOI.set(solver, MOI.NLPBlock(), NLPBlock)\n",
    "    # start point\n",
    "    params = MOI.add_variables(solver, npar)    \n",
    "    par0   = Vector{T}(undef, npar)\n",
    "    modelpar_to_optimpar!(par0, m)    \n",
    "    for i in 1:npar\n",
    "        MOI.set(solver, MOI.VariablePrimalStart(), params[i], par0[i])\n",
    "    end\n",
    "    MOI.set(solver, MOI.ObjectiveSense(), MOI.MAX_SENSE)\n",
    "    # optimize\n",
    "    MOI.optimize!(solver)\n",
    "    optstat = MOI.get(solver, MOI.TerminationStatus())\n",
    "    optstat in (MOI.LOCALLY_SOLVED, MOI.ALMOST_LOCALLY_SOLVED) || \n",
    "        @warn(\"Optimization unsuccesful; got $optstat\")\n",
    "    # update parameters and refresh gradient\n",
    "    xsol = [MOI.get(solver, MOI.VariablePrimal(), MOI.VariableIndex(i)) for i in 1:npar]\n",
    "    optimpar_to_modelpar!(m, xsol)\n",
    "    logl!(m, true)\n",
    "    m\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ‚ó∫(n::Integer)\n",
    "\n",
    "Triangular number `n * (n + 1) / 2`.\n",
    "\"\"\"\n",
    "@inline ‚ó∫(n::Integer) = (n * (n + 1)) >> 1\n",
    "\n",
    "\"\"\"\n",
    "    modelpar_to_optimpar!(par, m)\n",
    "\n",
    "Translate model parameters in `m` to optimization variables in `par`.\n",
    "\"\"\"\n",
    "function modelpar_to_optimpar!(\n",
    "        par :: Vector,\n",
    "        m   :: LmmModel\n",
    "    )\n",
    "    p = size(m.data[1].X, 2)\n",
    "    q = size(m.data[1].Z, 2)\n",
    "    # Œ≤\n",
    "    copyto!(par, m.Œ≤)\n",
    "    # L\n",
    "    offset = p + 1\n",
    "    @inbounds for j in 1:q, i in j:q\n",
    "        par[offset] = m.L[i, j]\n",
    "        offset += 1\n",
    "    end\n",
    "    # œÉ¬≤\n",
    "    par[end] = m.œÉ¬≤[1]\n",
    "    par\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    optimpar_to_modelpar!(m, par)\n",
    "\n",
    "Translate optimization variables in `par` to the model parameters in `m`.\n",
    "\"\"\"\n",
    "function optimpar_to_modelpar!(\n",
    "        m   :: LmmModel, \n",
    "        par :: Vector\n",
    "    )\n",
    "    p = size(m.data[1].X, 2)\n",
    "    q = size(m.data[1].Z, 2)\n",
    "    # Œ≤\n",
    "    copyto!(m.Œ≤, 1, par, 1, p)\n",
    "    # L\n",
    "    fill!(m.L, 0)\n",
    "    offset = p + 1\n",
    "    @inbounds for j in 1:q, i in j:q\n",
    "        m.L[i, j] = par[offset]\n",
    "        offset   += 1\n",
    "    end\n",
    "    # œÉ¬≤\n",
    "    m.œÉ¬≤[1] = par[end]    \n",
    "    m\n",
    "end\n",
    "\n",
    "function MOI.initialize(\n",
    "        m                  :: LmmModel, \n",
    "        requested_features :: Vector{Symbol}\n",
    "    )\n",
    "    for feat in requested_features\n",
    "        if !(feat in MOI.features_available(m))\n",
    "            error(\"Unsupported feature $feat\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "MOI.features_available(m::LmmModel) = [:Grad, :Hess, :Jac]\n",
    "\n",
    "function MOI.eval_objective(\n",
    "        m   :: LmmModel, \n",
    "        par :: Vector\n",
    "    )\n",
    "    optimpar_to_modelpar!(m, par)\n",
    "    logl!(m, false) # don't need gradient here\n",
    "end\n",
    "\n",
    "function MOI.eval_objective_gradient(\n",
    "        m    :: LmmModel, \n",
    "        grad :: Vector, \n",
    "        par  :: Vector\n",
    "    )\n",
    "    p = size(m.data[1].X, 2)\n",
    "    q = size(m.data[1].Z, 2)\n",
    "    optimpar_to_modelpar!(m, par) \n",
    "    obj = logl!(m, true)\n",
    "    # gradient wrt Œ≤\n",
    "    copyto!(grad, m.‚àáŒ≤)\n",
    "    # gradient wrt L\n",
    "    offset = p + 1\n",
    "    @inbounds for j in 1:q, i in j:q\n",
    "        grad[offset] = m.‚àáL[i, j]\n",
    "        offset += 1\n",
    "    end\n",
    "    # gradient with respect to œÉ¬≤\n",
    "    grad[end] = m.‚àáœÉ¬≤[1]\n",
    "    # return objective\n",
    "    obj\n",
    "end\n",
    "\n",
    "function MOI.eval_constraint(m::LmmModel, g, par)\n",
    "    p = size(m.data[1].X, 2)\n",
    "    q = size(m.data[1].Z, 2)\n",
    "    gidx   = 1\n",
    "    offset = p + 1\n",
    "    @inbounds for j in 1:q, i in j:q\n",
    "        if i == j\n",
    "            g[gidx] = par[offset]\n",
    "            gidx   += 1\n",
    "        end\n",
    "        offset += 1\n",
    "    end\n",
    "    g[end] = par[end]\n",
    "    g\n",
    "end\n",
    "\n",
    "function MOI.jacobian_structure(m::LmmModel)\n",
    "    p    = size(m.data[1].X, 2)\n",
    "    q    = size(m.data[1].Z, 2)\n",
    "    row  = collect(1:(q + 1))\n",
    "    col  = Int[]\n",
    "    offset = p + 1\n",
    "    for j in 1:q, i in j:q\n",
    "        (i == j) && push!(col, offset)\n",
    "        offset += 1\n",
    "    end\n",
    "    push!(col, offset)\n",
    "    [(row[i], col[i]) for i in 1:length(row)]\n",
    "end\n",
    "\n",
    "MOI.eval_constraint_jacobian(m::LmmModel, J, par) = fill!(J, 1)\n",
    "\n",
    "function MOI.hessian_lagrangian_structure(m::LmmModel)\n",
    "    p    = size(m.data[1].X, 2)\n",
    "    q    = size(m.data[1].Z, 2)    \n",
    "    q‚ó∫   = ‚ó∫(q)\n",
    "    # we work on the upper triangular part of the Hessian\n",
    "    arr1 = Vector{Int}(undef, ‚ó∫(p) + ‚ó∫(q‚ó∫) + q‚ó∫ + 1)\n",
    "    arr2 = Vector{Int}(undef, ‚ó∫(p) + ‚ó∫(q‚ó∫) + q‚ó∫ + 1)\n",
    "    # HŒ≤Œ≤ block\n",
    "    idx  = 1    \n",
    "    for j in 1:p, i in 1:j\n",
    "        arr1[idx] = i\n",
    "        arr2[idx] = j\n",
    "        idx      += 1\n",
    "    end\n",
    "    # HLL block\n",
    "    for j in 1:q‚ó∫, i in 1:j\n",
    "        arr1[idx] = p + i\n",
    "        arr2[idx] = p + j\n",
    "        idx      += 1\n",
    "    end\n",
    "    # HLœÉ¬≤ block\n",
    "    for i in (p + 1):(p + q‚ó∫)\n",
    "        arr1[idx] = i\n",
    "        arr2[idx] = p + q‚ó∫ + 1\n",
    "        idx      += 1\n",
    "    end\n",
    "    # HœÉ¬≤œÉ¬≤ block\n",
    "    arr1[idx] = p + q‚ó∫ + 1\n",
    "    arr2[idx] = p + q‚ó∫ + 1\n",
    "    [(arr1[i], arr2[i]) for i in 1:length(arr1)]\n",
    "end\n",
    "\n",
    "function MOI.eval_hessian_lagrangian(\n",
    "        m   :: LmmModel, \n",
    "        H   :: AbstractVector{T},\n",
    "        par :: AbstractVector{T}, \n",
    "        œÉ   :: T, \n",
    "        Œº   :: AbstractVector{T}\n",
    "    ) where {T}    \n",
    "    p  = size(m.data[1].X, 2)\n",
    "    q  = size(m.data[1].Z, 2)    \n",
    "    q‚ó∫ = ‚ó∫(q)\n",
    "    optimpar_to_modelpar!(m, par)\n",
    "    logl!(m, true, true)\n",
    "    # HŒ≤Œ≤ block\n",
    "    idx = 1    \n",
    "    @inbounds for j in 1:p, i in 1:j\n",
    "        H[idx] = m.HŒ≤Œ≤[i, j]\n",
    "        idx   += 1\n",
    "    end\n",
    "    # HLL block\n",
    "    @inbounds for j in 1:q‚ó∫, i in 1:j\n",
    "        H[idx] = m.HLL[i, j]\n",
    "        idx   += 1\n",
    "    end\n",
    "    # HLœÉ¬≤ block\n",
    "    @inbounds for j in 1:q, i in j:q\n",
    "        H[idx] = m.HœÉ¬≤L[i, j]\n",
    "        idx   += 1\n",
    "    end\n",
    "    # HœÉ¬≤œÉ¬≤ block\n",
    "    H[idx] = m.HœÉ¬≤œÉ¬≤[1, 1]\n",
    "    lmul!(œÉ, H)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. (20 pts) Test drive\n",
    "\n",
    "Now we can run any NLP solver (supported by MathOptInterface.jl) to compute the MLE. For grading purpose, let's use the `:LD_MMA` ([Method of Moving Asymptotes](https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/#mma-method-of-moving-asymptotes-and-ccsa)) algorithm in NLopt.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective value at starting point: -3.3626049341044296e6\n",
      "\n",
      "  0.682982 seconds (2.35 M allocations: 117.570 MiB, 86.17% compilation time)\n",
      "objective value at solution: -2.8400587866501906e6)\n",
      "solution values:\n",
      "lmm.Œ≤ = [0.18147761275318702, 6.500383554079115, -3.499864289622533, 0.9997119258250217, 4.9992294818666485]\n",
      "lmm.œÉ¬≤ = [1.4987345756252395]\n",
      "lmm.L * transpose(lmm.L) = [1.98362662028152 0.06578009192551917 0.0551714489185263; 0.06578009192551917 1.2814411901189633 -0.09059652721670342; 0.0551714489185263 -0.09059652721670342 0.9434277102704337]\n",
      "gradient @ solution:\n",
      "lmm.‚àáŒ≤ = [0.020713646000421804, -0.007673049072174365, -0.007696684597899406, -0.0006715494805469291, -0.0007028968814868364]\n",
      "lmm.‚àáœÉ¬≤ = [-0.009189199374304735]\n",
      "lmm.‚àáL = [-0.0001604167818254836 -0.002991795288477183 0.053539153576452565; 0.001976753047221549 0.00021100492663237756 0.0013633095754418173; 0.07847071933983868 0.0006940645047697002 0.010655693226430092]\n",
      "norm([lmm.‚àáŒ≤; vec(LowerTriangular(lmm.‚àáL)); lmm.‚àáœÉ¬≤]) = 0.08311566230851339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08311566230851339"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize from least squares\n",
    "init_ls!(lmm)\n",
    "println(\"objective value at starting point: \", logl!(lmm)); println()\n",
    "\n",
    "# NLopt (LD_MMA) obj. val = -2.8400587866501966e6\n",
    "NLopt_solver = NLopt.Optimizer()\n",
    "MOI.set(NLopt_solver, MOI.RawOptimizerAttribute(\"algorithm\"), :LD_MMA)\n",
    "@time fit!(lmm, NLopt_solver)\n",
    "\n",
    "println(\"objective value at solution: $(logl!(lmm)))\")\n",
    "println(\"solution values:\")\n",
    "@show lmm.Œ≤\n",
    "@show lmm.œÉ¬≤\n",
    "@show lmm.L * transpose(lmm.L)\n",
    "println(\"gradient @ solution:\")\n",
    "@show lmm.‚àáŒ≤\n",
    "@show lmm.‚àáœÉ¬≤\n",
    "@show lmm.‚àáL\n",
    "@show norm([lmm.‚àáŒ≤; vec(LowerTriangular(lmm.‚àáL)); lmm.‚àáœÉ¬≤])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctness\n",
    "\n",
    "You get 10 points if the following code does not throw `AssertError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective at solution should be close enough to the optimal\n",
    "@assert logl!(lmm) > -2.840059e6\n",
    "# gradient at solution should be small enough\n",
    "@assert norm([lmm.‚àáŒ≤; vec(LowerTriangular(lmm.‚àáL)); lmm.‚àáœÉ¬≤]) < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "My median run time is 50ms. You get 10 points if your median time is within 1s(=1000ms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 55 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m91.441 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 92.414 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m91.941 ms               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m91.953 ms\u001b[22m\u001b[39m ¬± \u001b[32m253.821 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñÅ\u001b[39m\u001b[39m‚ñà\u001b[32m‚ñÅ\u001b[39m\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m \u001b[39m‚ñÅ\n",
       "  91.4 ms\u001b[90m         Histogram: frequency by time\u001b[39m         92.4 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m18.18 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m523\u001b[39m."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLopt_solver = NLopt.Optimizer()\n",
    "MOI.set(NLopt_solver, MOI.RawOptimizerAttribute(\"algorithm\"), :LD_MMA)\n",
    "bm_mma = @benchmark fit!($lmm, $(NLopt_solver)) setup=(init_ls!(lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "clamp(1 / (median(bm_mma).time / 1e9) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. (10 pts) Gradient free vs gradient-based methods\n",
    "\n",
    "Advantage of using a modelling tool such as MathOptInterface.jl is that we can easily switch the backend solvers. For a research problem, we never know beforehand which solver works best. \n",
    "\n",
    "Try different solvers in the NLopt.jl and Ipopt.jl packages. Compare the results in terms of run times (the shorter the better), objective values at solution (the larger the better), and gradients at solution (closer to 0 the better). Summarize what you find.\n",
    "\n",
    "See this [page](https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/) for the descriptions of algorithms in NLopt.\n",
    "\n",
    "Documentation for the Ipopt can be found [here](https://coin-or.github.io/Ipopt/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vector of solvers to compare\n",
    "solvers = [\"NLopt (LN_COBYLA, gradient free)\", \"NLopt (LD_MMA, gradient-based)\", \n",
    "    \"Ipopt (L-BFGS)\"]\n",
    "\n",
    "function setup_solver(s::String)\n",
    "    if s == \"NLopt (LN_COBYLA, gradient free)\"\n",
    "        solver = NLopt.Optimizer()\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"algorithm\"), :LN_COBYLA)\n",
    "    elseif s == \"NLopt (LD_MMA, gradient-based)\"\n",
    "        solver = NLopt.Optimizer()\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"algorithm\"), :LD_MMA)\n",
    "    elseif s == \"Ipopt (L-BFGS)\"\n",
    "        solver = Ipopt.Optimizer()\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"print_level\"), 0)\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"hessian_approximation\"), \"limited-memory\")\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"tol\"), 1e-6)\n",
    "    elseif s == \"Ipopt (use FIM)\"\n",
    "        # Ipopt (use Hessian) obj val = -2.8400587866468e6\n",
    "        solver = Ipopt.Optimizer()\n",
    "        MOI.set(solver, MOI.RawOptimizerAttribute(\"print_level\"), 0)        \n",
    "    else\n",
    "        error(\"unrecognized solver $s\")\n",
    "    end\n",
    "    solver\n",
    "end\n",
    "\n",
    "# containers for results\n",
    "runtime = zeros(length(solvers))\n",
    "objvals = zeros(length(solvers))\n",
    "gradnrm = zeros(length(solvers))\n",
    "\n",
    "for i in 1:length(solvers)\n",
    "    solver = setup_solver(solvers[i])\n",
    "    bm = @benchmark fit!($lmm, $solver) setup = (init_ls!(lmm))\n",
    "    runtime[i] = median(bm).time / 1e9\n",
    "    objvals[i] = logl!(lmm, true)\n",
    "    gradnrm[i] = norm([lmm.‚àáŒ≤; vec(LowerTriangular(lmm.‚àáL)); lmm.‚àáœÉ¬≤])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ\u001b[1m                           Solver \u001b[0m‚îÇ\u001b[1m Runtime \u001b[0m‚îÇ\u001b[1m          Log-Like \u001b[0m‚îÇ\u001b[1m Gradiant Norm \u001b[0m‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ NLopt (LN_COBYLA, gradient free) ‚îÇ    0.45 ‚îÇ -2840081.03741792 ‚îÇ  839.00644376 ‚îÇ\n",
      "‚îÇ   NLopt (LD_MMA, gradient-based) ‚îÇ    0.09 ‚îÇ -2840058.78665019 ‚îÇ    0.08311566 ‚îÇ\n",
      "‚îÇ                   Ipopt (L-BFGS) ‚îÇ    1.39 ‚îÇ -2840058.78664680 ‚îÇ    0.00139067 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# display results\n",
    "pretty_table(\n",
    "    hcat(solvers, runtime, objvals, gradnrm),\n",
    "    header = [\"Solver\", \"Runtime\", \"Log-Like\", \"Gradiant Norm\"],\n",
    "    formatters = (ft_printf(\"%5.2f\", 2), ft_printf(\"%8.8f\", 3:4))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. (10 pts) Compare with existing art\n",
    "\n",
    "Let's compare our method with lme4 package in R and MixedModels.jl package in Julia. Both lme4 and MixedModels.jl are developed mainly by Doug Bates. Summarize what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "method  = [\"My method\", \"lme4\", \"MixedModels.jl\"]\n",
    "runtime = zeros(3)  # record the run times\n",
    "loglike = zeros(3); # record the log-likelihood at MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.8400587866501906e6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = setup_solver(\"NLopt (LD_MMA, gradient-based)\")\n",
    "bm_257 = @benchmark fit!($lmm, $solver) setup=(init_ls!(lmm))\n",
    "runtime[1] = (median(bm_257).time) / 1e9\n",
    "loglike[1] = logl!(lmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lme4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m‚îå \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mRCall.jl: Loading required package: Matrix\n",
      "\u001b[33m\u001b[1m‚îî \u001b[22m\u001b[39m\u001b[90m@ RCall ~/.julia/packages/RCall/LWzAQ/src/io.jl:172\u001b[39m\n",
      "\u001b[33m\u001b[1m‚îå \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mRCall.jl: Rows: 1744977 Columns: 8\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39mDelimiter: \",\"\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39mdbl (8): ID, Y, X1, X2, X3, X4, Z1, Z2\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[33m\u001b[1m‚îî \u001b[22m\u001b[39m\u001b[90m@ RCall ~/.julia/packages/RCall/LWzAQ/src/io.jl:172\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "# A tibble: 1,744,977 √ó 8\n",
       "      ID        Y     X1      X2     X3      X4      Z1      Z2\n",
       "   <dbl>    <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n",
       " 1     1   9.52    0.202 -0.463   0.798  0.734   0.685  -0.570 \n",
       " 2     1  24.4     1.59  -1.95    1.20   1.43    1.64    0.369 \n",
       " 3     1  -1.99    0.378 -0.0367  1.63  -1.15   -0.818   2.83  \n",
       " 4     1 -17.4    -1.88   0.375  -0.498 -0.253   1.56    1.68  \n",
       " 5     1  -0.0704  0.658 -0.165   0.780 -1.23   -0.0288 -1.09  \n",
       " 6     1  -0.853   0.458 -0.313  -0.512 -0.800  -0.331   1.98  \n",
       " 7     1  -1.80    0.220  0.328   1.32  -1.01   -0.363  -0.0703\n",
       " 8     1   5.88    1.30   0.889  -0.854  0.0714 -0.658  -0.0339\n",
       " 9     1  -9.21   -1.43  -0.522  -0.119 -0.580  -0.155  -1.89  \n",
       "10     1 -11.3    -0.468 -0.700   0.872 -1.82    1.80    0.492 \n",
       "# ‚Ñπ 1,744,967 more rows\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(lme4)\n",
    "library(readr)\n",
    "library(magrittr)\n",
    "\n",
    "testdata <- read_csv(\"lmm_data.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{RealSxp}\n",
       "   user  system elapsed \n",
       " 84.058   8.406  92.470 \n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "rtime <- system.time(mmod <- \n",
    "  lmer(Y ~ X1 + X2 + X3 + X4 + (1 + Z1 + Z2 | ID), testdata, REML = FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "rtime <- rtime[\"elapsed\"]\n",
    "summary(mmod)\n",
    "rlogl <- logLik(mmod)\n",
    "\"\"\"\n",
    "runtime[2] = @rget rtime\n",
    "loglike[2] = @rget rlogl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MixedModels.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>1744977√ó8 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">1744952 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">ID</th><th style = \"text-align: left;\">Y</th><th style = \"text-align: left;\">X1</th><th style = \"text-align: left;\">X2</th><th style = \"text-align: left;\">X3</th><th style = \"text-align: left;\">X4</th><th style = \"text-align: left;\">Z1</th><th style = \"text-align: left;\">Z2</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">9.52102</td><td style = \"text-align: right;\">0.201821</td><td style = \"text-align: right;\">-0.463234</td><td style = \"text-align: right;\">0.797731</td><td style = \"text-align: right;\">0.73357</td><td style = \"text-align: right;\">0.685476</td><td style = \"text-align: right;\">-0.569622</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">24.4063</td><td style = \"text-align: right;\">1.58557</td><td style = \"text-align: right;\">-1.94608</td><td style = \"text-align: right;\">1.19787</td><td style = \"text-align: right;\">1.43149</td><td style = \"text-align: right;\">1.63962</td><td style = \"text-align: right;\">0.369053</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-1.99215</td><td style = \"text-align: right;\">0.378332</td><td style = \"text-align: right;\">-0.0367002</td><td style = \"text-align: right;\">1.63072</td><td style = \"text-align: right;\">-1.15031</td><td style = \"text-align: right;\">-0.817843</td><td style = \"text-align: right;\">2.83422</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-17.4233</td><td style = \"text-align: right;\">-1.8826</td><td style = \"text-align: right;\">0.374561</td><td style = \"text-align: right;\">-0.49786</td><td style = \"text-align: right;\">-0.253248</td><td style = \"text-align: right;\">1.56433</td><td style = \"text-align: right;\">1.67857</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-0.0704245</td><td style = \"text-align: right;\">0.658283</td><td style = \"text-align: right;\">-0.165487</td><td style = \"text-align: right;\">0.77951</td><td style = \"text-align: right;\">-1.22763</td><td style = \"text-align: right;\">-0.0287779</td><td style = \"text-align: right;\">-1.09172</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-0.853357</td><td style = \"text-align: right;\">0.457784</td><td style = \"text-align: right;\">-0.313387</td><td style = \"text-align: right;\">-0.512299</td><td style = \"text-align: right;\">-0.800278</td><td style = \"text-align: right;\">-0.330632</td><td style = \"text-align: right;\">1.97609</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-1.80061</td><td style = \"text-align: right;\">0.220461</td><td style = \"text-align: right;\">0.327879</td><td style = \"text-align: right;\">1.32209</td><td style = \"text-align: right;\">-1.01336</td><td style = \"text-align: right;\">-0.362947</td><td style = \"text-align: right;\">-0.0703055</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">5.88119</td><td style = \"text-align: right;\">1.30135</td><td style = \"text-align: right;\">0.88884</td><td style = \"text-align: right;\">-0.853941</td><td style = \"text-align: right;\">0.0714372</td><td style = \"text-align: right;\">-0.658202</td><td style = \"text-align: right;\">-0.0338648</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-9.20504</td><td style = \"text-align: right;\">-1.43248</td><td style = \"text-align: right;\">-0.521638</td><td style = \"text-align: right;\">-0.119287</td><td style = \"text-align: right;\">-0.579596</td><td style = \"text-align: right;\">-0.154869</td><td style = \"text-align: right;\">-1.88707</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-11.2909</td><td style = \"text-align: right;\">-0.46827</td><td style = \"text-align: right;\">-0.699709</td><td style = \"text-align: right;\">0.871668</td><td style = \"text-align: right;\">-1.81529</td><td style = \"text-align: right;\">1.79726</td><td style = \"text-align: right;\">0.492339</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">8.9367</td><td style = \"text-align: right;\">2.00212</td><td style = \"text-align: right;\">1.1577</td><td style = \"text-align: right;\">-0.973746</td><td style = \"text-align: right;\">-0.784991</td><td style = \"text-align: right;\">-2.12648</td><td style = \"text-align: right;\">-1.68961</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-0.496904</td><td style = \"text-align: right;\">-0.480658</td><td style = \"text-align: right;\">0.1732</td><td style = \"text-align: right;\">-1.27733</td><td style = \"text-align: right;\">0.571911</td><td style = \"text-align: right;\">-0.802521</td><td style = \"text-align: right;\">0.584438</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">-0.139879</td><td style = \"text-align: right;\">0.597359</td><td style = \"text-align: right;\">-0.894785</td><td style = \"text-align: right;\">-0.904349</td><td style = \"text-align: right;\">-1.10844</td><td style = \"text-align: right;\">0.106724</td><td style = \"text-align: right;\">-0.5961</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744966</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">14.3459</td><td style = \"text-align: right;\">2.53537</td><td style = \"text-align: right;\">-0.385281</td><td style = \"text-align: right;\">0.374004</td><td style = \"text-align: right;\">-1.06646</td><td style = \"text-align: right;\">-0.881868</td><td style = \"text-align: right;\">-0.524693</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744967</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-1.86731</td><td style = \"text-align: right;\">-0.156314</td><td style = \"text-align: right;\">-0.359602</td><td style = \"text-align: right;\">-1.00392</td><td style = \"text-align: right;\">-0.463548</td><td style = \"text-align: right;\">-1.40846</td><td style = \"text-align: right;\">0.289986</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744968</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-3.12427</td><td style = \"text-align: right;\">-0.393863</td><td style = \"text-align: right;\">-0.491481</td><td style = \"text-align: right;\">1.55365</td><td style = \"text-align: right;\">-0.776784</td><td style = \"text-align: right;\">0.688556</td><td style = \"text-align: right;\">-1.16616</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744969</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-3.20226</td><td style = \"text-align: right;\">-0.126944</td><td style = \"text-align: right;\">0.601992</td><td style = \"text-align: right;\">-0.960992</td><td style = \"text-align: right;\">-0.300833</td><td style = \"text-align: right;\">1.07374</td><td style = \"text-align: right;\">0.649807</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744970</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">0.0979076</td><td style = \"text-align: right;\">-0.0942822</td><td style = \"text-align: right;\">-0.017406</td><td style = \"text-align: right;\">1.01639</td><td style = \"text-align: right;\">-0.111906</td><td style = \"text-align: right;\">-0.708675</td><td style = \"text-align: right;\">0.0446113</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744971</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">6.84005</td><td style = \"text-align: right;\">0.286095</td><td style = \"text-align: right;\">-0.995131</td><td style = \"text-align: right;\">-0.293129</td><td style = \"text-align: right;\">0.193649</td><td style = \"text-align: right;\">-1.03079</td><td style = \"text-align: right;\">-1.9487</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744972</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">8.44826</td><td style = \"text-align: right;\">-0.0458988</td><td style = \"text-align: right;\">-0.00257329</td><td style = \"text-align: right;\">-1.31491</td><td style = \"text-align: right;\">1.51216</td><td style = \"text-align: right;\">0.0174882</td><td style = \"text-align: right;\">0.530319</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744973</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-5.13234</td><td style = \"text-align: right;\">-1.11932</td><td style = \"text-align: right;\">-1.06951</td><td style = \"text-align: right;\">-0.339256</td><td style = \"text-align: right;\">-0.500339</td><td style = \"text-align: right;\">0.737606</td><td style = \"text-align: right;\">1.58472</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744974</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-0.530812</td><td style = \"text-align: right;\">-0.850859</td><td style = \"text-align: right;\">0.00500998</td><td style = \"text-align: right;\">-0.274531</td><td style = \"text-align: right;\">1.01461</td><td style = \"text-align: right;\">0.382234</td><td style = \"text-align: right;\">-0.435956</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744975</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-8.88652</td><td style = \"text-align: right;\">-0.762326</td><td style = \"text-align: right;\">0.154867</td><td style = \"text-align: right;\">-0.933923</td><td style = \"text-align: right;\">-0.931906</td><td style = \"text-align: right;\">0.797417</td><td style = \"text-align: right;\">0.888702</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744976</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">-1.42159</td><td style = \"text-align: right;\">-0.672599</td><td style = \"text-align: right;\">-1.25194</td><td style = \"text-align: right;\">-0.518835</td><td style = \"text-align: right;\">-0.0647723</td><td style = \"text-align: right;\">-1.48993</td><td style = \"text-align: right;\">-0.00689683</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1744977</td><td style = \"text-align: left;\">1000</td><td style = \"text-align: right;\">3.79889</td><td style = \"text-align: right;\">-1.21758</td><td style = \"text-align: right;\">-1.49033</td><td style = \"text-align: right;\">1.04599</td><td style = \"text-align: right;\">0.459857</td><td style = \"text-align: right;\">0.628323</td><td style = \"text-align: right;\">0.856971</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& ID & Y & X1 & X2 & X3 & X4 & Z1 & Z2\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 9.52102 & 0.201821 & -0.463234 & 0.797731 & 0.73357 & 0.685476 & -0.569622 \\\\\n",
       "\t2 & 1 & 24.4063 & 1.58557 & -1.94608 & 1.19787 & 1.43149 & 1.63962 & 0.369053 \\\\\n",
       "\t3 & 1 & -1.99215 & 0.378332 & -0.0367002 & 1.63072 & -1.15031 & -0.817843 & 2.83422 \\\\\n",
       "\t4 & 1 & -17.4233 & -1.8826 & 0.374561 & -0.49786 & -0.253248 & 1.56433 & 1.67857 \\\\\n",
       "\t5 & 1 & -0.0704245 & 0.658283 & -0.165487 & 0.77951 & -1.22763 & -0.0287779 & -1.09172 \\\\\n",
       "\t6 & 1 & -0.853357 & 0.457784 & -0.313387 & -0.512299 & -0.800278 & -0.330632 & 1.97609 \\\\\n",
       "\t7 & 1 & -1.80061 & 0.220461 & 0.327879 & 1.32209 & -1.01336 & -0.362947 & -0.0703055 \\\\\n",
       "\t8 & 1 & 5.88119 & 1.30135 & 0.88884 & -0.853941 & 0.0714372 & -0.658202 & -0.0338648 \\\\\n",
       "\t9 & 1 & -9.20504 & -1.43248 & -0.521638 & -0.119287 & -0.579596 & -0.154869 & -1.88707 \\\\\n",
       "\t10 & 1 & -11.2909 & -0.46827 & -0.699709 & 0.871668 & -1.81529 & 1.79726 & 0.492339 \\\\\n",
       "\t11 & 1 & 8.9367 & 2.00212 & 1.1577 & -0.973746 & -0.784991 & -2.12648 & -1.68961 \\\\\n",
       "\t12 & 1 & -0.496904 & -0.480658 & 0.1732 & -1.27733 & 0.571911 & -0.802521 & 0.584438 \\\\\n",
       "\t13 & 1 & -0.139879 & 0.597359 & -0.894785 & -0.904349 & -1.10844 & 0.106724 & -0.5961 \\\\\n",
       "\t14 & 1 & -8.71947 & -0.511146 & -1.338 & -1.18855 & -1.8141 & 0.469028 & -0.172564 \\\\\n",
       "\t15 & 1 & -2.58409 & -0.597996 & 0.059796 & -0.655992 & 0.0857626 & -1.16351 & -0.240554 \\\\\n",
       "\t16 & 1 & -5.81281 & 0.411499 & 0.437668 & -0.725361 & -0.812424 & 1.99023 & -0.768594 \\\\\n",
       "\t17 & 1 & -0.596476 & 0.0463844 & 0.0538646 & 0.663663 & 0.51955 & 2.30564 & 0.4257 \\\\\n",
       "\t18 & 1 & -3.18641 & -1.49591 & 0.659436 & 0.956284 & 1.24877 & -0.824118 & 0.177151 \\\\\n",
       "\t19 & 1 & 1.56221 & -0.606838 & 1.08345 & 0.163253 & 1.84409 & -0.511557 & -0.994212 \\\\\n",
       "\t20 & 1 & 3.02138 & 0.0405701 & 0.0647205 & 1.22975 & -0.0210971 & -1.50206 & -0.414032 \\\\\n",
       "\t21 & 1 & 22.7553 & 2.22447 & 0.917703 & 0.621901 & 2.02733 & -0.0768099 & -0.0520619 \\\\\n",
       "\t22 & 1 & 3.70676 & 0.56003 & -1.49019 & 0.368436 & -1.24426 & -0.853134 & 0.712161 \\\\\n",
       "\t23 & 1 & -8.04279 & -0.823574 & -0.627208 & -0.956862 & -1.0348 & -0.873069 & -0.856131 \\\\\n",
       "\t24 & 1 & -2.33705 & -0.721538 & 0.362801 & 0.548455 & 0.894375 & 1.89845 & 1.32574 \\\\\n",
       "\t25 & 1 & 14.8916 & 0.626803 & -2.96424 & -0.747008 & 0.0964266 & 0.117514 & 1.64184 \\\\\n",
       "\t26 & 1 & 18.3082 & 0.770025 & -0.257942 & 0.513041 & 2.25855 & 0.571801 & -1.39796 \\\\\n",
       "\t27 & 1 & 1.19626 & 0.0607296 & 0.315506 & -0.279184 & 0.42981 & -0.546869 & 0.118436 \\\\\n",
       "\t28 & 1 & -15.2916 & -0.830792 & 2.3629 & -0.210138 & -0.659754 & -0.717479 & 0.223425 \\\\\n",
       "\t29 & 1 & 8.53769 & 1.02613 & -0.0021617 & -1.35241 & -0.0927837 & -0.666525 & -0.0567915 \\\\\n",
       "\t30 & 1 & -10.3919 & -0.465915 & 0.560413 & -1.41106 & -0.921584 & -1.17228 & -0.219102 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1744977√ó8 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m‚îÇ\u001b[1m ID     \u001b[0m\u001b[1m Y           \u001b[0m\u001b[1m X1         \u001b[0m\u001b[1m X2          \u001b[0m\u001b[1m X3        \u001b[0m\u001b[1m X4        \u001b[0m ‚ãØ\n",
       "         ‚îÇ\u001b[90m String \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m ‚ãØ\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "       1 ‚îÇ 1         9.52102     0.201821   -0.463234     0.797731   0.73357   ‚ãØ\n",
       "       2 ‚îÇ 1        24.4063      1.58557    -1.94608      1.19787    1.43149\n",
       "       3 ‚îÇ 1        -1.99215     0.378332   -0.0367002    1.63072   -1.15031\n",
       "       4 ‚îÇ 1       -17.4233     -1.8826      0.374561    -0.49786   -0.253248\n",
       "       5 ‚îÇ 1        -0.0704245   0.658283   -0.165487     0.77951   -1.22763   ‚ãØ\n",
       "       6 ‚îÇ 1        -0.853357    0.457784   -0.313387    -0.512299  -0.800278\n",
       "       7 ‚îÇ 1        -1.80061     0.220461    0.327879     1.32209   -1.01336\n",
       "       8 ‚îÇ 1         5.88119     1.30135     0.88884     -0.853941   0.0714372\n",
       "       9 ‚îÇ 1        -9.20504    -1.43248    -0.521638    -0.119287  -0.579596  ‚ãØ\n",
       "      10 ‚îÇ 1       -11.2909     -0.46827    -0.699709     0.871668  -1.81529\n",
       "      11 ‚îÇ 1         8.9367      2.00212     1.1577      -0.973746  -0.784991\n",
       "    ‚ãÆ    ‚îÇ   ‚ãÆ          ‚ãÆ           ‚ãÆ            ‚ãÆ           ‚ãÆ          ‚ãÆ      ‚ã±\n",
       " 1744968 ‚îÇ 1000     -3.12427    -0.393863   -0.491481     1.55365   -0.776784\n",
       " 1744969 ‚îÇ 1000     -3.20226    -0.126944    0.601992    -0.960992  -0.300833  ‚ãØ\n",
       " 1744970 ‚îÇ 1000      0.0979076  -0.0942822  -0.017406     1.01639   -0.111906\n",
       " 1744971 ‚îÇ 1000      6.84005     0.286095   -0.995131    -0.293129   0.193649\n",
       " 1744972 ‚îÇ 1000      8.44826    -0.0458988  -0.00257329  -1.31491    1.51216\n",
       " 1744973 ‚îÇ 1000     -5.13234    -1.11932    -1.06951     -0.339256  -0.500339  ‚ãØ\n",
       " 1744974 ‚îÇ 1000     -0.530812   -0.850859    0.00500998  -0.274531   1.01461\n",
       " 1744975 ‚îÇ 1000     -8.88652    -0.762326    0.154867    -0.933923  -0.931906\n",
       " 1744976 ‚îÇ 1000     -1.42159    -0.672599   -1.25194     -0.518835  -0.0647723\n",
       " 1744977 ‚îÇ 1000      3.79889    -1.21758    -1.49033      1.04599    0.459857  ‚ãØ\n",
       "\u001b[36m                                              2 columns and 1744956 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "testdata = CSV.File(\"lmm_data.csv\", types = Dict(1=>String)) |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m‚îå \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell. \n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`. \n",
      "\u001b[33m\u001b[1m‚îÇ \u001b[22m\u001b[39m - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.\n",
      "\u001b[33m\u001b[1m‚îî \u001b[22m\u001b[39m\u001b[90m@ ProgressMeter ~/.julia/packages/ProgressMeter/sN2xr/src/ProgressMeter.jl:618\u001b[39m\n",
      "\r",
      "\u001b[32mMinimizing 189 \t Time: 0:00:00 ( 0.55 ms/it)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6062183545"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mj = fit(MixedModel, @formula(Y ~ X1 + X2 + X3 + X4 + (1 + Z1 + Z2 | ID)), testdata)\n",
    "bm_mm = @benchmark fit(MixedModel, @formula(Y ~ X1 + X2 + X3 + X4 + (1 + Z1 + Z2 | ID)), $testdata)\n",
    "loglike[3] = loglikelihood(mj)\n",
    "runtime[3] = median(bm_mm).time / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 8 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m566.675 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m769.682 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m1.01% ‚Ä¶ 22.94%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m606.218 ms               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m3.24%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m629.265 ms\u001b[22m\u001b[39m ¬± \u001b[32m 64.796 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m5.86% ¬±  7.56%\n",
       "\n",
       "  \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m‚ñà\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñà\u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m \u001b[39m‚ñÅ\n",
       "  567 ms\u001b[90m           Histogram: frequency by time\u001b[39m          770 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m841.87 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m7895\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "\\begin{tabular}\n",
       "{l | r | r | r | r | r}\n",
       " & Est. & SE & z & p & $\\sigma_\\text{ID}$ \\\\\n",
       "\\hline\n",
       "(Intercept) & 0.1815 & 0.0445 & 4.08 & <1e-04 & 1.4086 \\\\\n",
       "X1 & 6.5004 & 0.0009 & 7000.80 & <1e-99 &   \\\\\n",
       "X2 & -3.4999 & 0.0009 & -3768.92 & <1e-99 &   \\\\\n",
       "X3 & 0.9997 & 0.0009 & 1078.16 & <1e-99 &   \\\\\n",
       "X4 & 4.9992 & 0.0009 & 5391.08 & <1e-99 &   \\\\\n",
       "Z2 &  &  &  &  & 0.9711 \\\\\n",
       "Z1 &  &  &  &  & 1.1319 \\\\\n",
       "Residual & 1.2242 &  &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "|             |    Est. |     SE |        z |      p |   œÉ_ID |\n",
       "|:----------- | -------:| ------:| --------:| ------:| ------:|\n",
       "| (Intercept) |  0.1815 | 0.0445 |     4.08 | <1e-04 | 1.4086 |\n",
       "| X1          |  6.5004 | 0.0009 |  7000.80 | <1e-99 |        |\n",
       "| X2          | -3.4999 | 0.0009 | -3768.92 | <1e-99 |        |\n",
       "| X3          |  0.9997 | 0.0009 |  1078.16 | <1e-99 |        |\n",
       "| X4          |  4.9992 | 0.0009 |  5391.08 | <1e-99 |        |\n",
       "| Z2          |         |        |          |        | 0.9711 |\n",
       "| Z1          |         |        |          |        | 1.1319 |\n",
       "| Residual    |  1.2242 |        |          |        |        |\n"
      ],
      "text/plain": [
       "Linear mixed model fit by maximum likelihood\n",
       " Y ~ 1 + X1 + X2 + X3 + X4 + (1 + Z1 + Z2 | ID)\n",
       "     logLik     -2 logLik        AIC           AICc          BIC      \n",
       " -2840058.7867  5680117.5735  5680141.5735  5680141.5737  5680290.0405\n",
       "\n",
       "Variance components:\n",
       "            Column   Variance Std.Dev.   Corr.\n",
       "ID       (Intercept)  1.984032 1.408557\n",
       "         Z1           1.281299 1.131945 +0.04\n",
       "         Z2           0.943004 0.971084 +0.04 -0.08\n",
       "Residual              1.498735 1.224228\n",
       " Number of obs: 1744977; levels of grouping factors: 1000\n",
       "\n",
       "  Fixed-effects parameters:\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "                 Coef.   Std. Error         z  Pr(>|z|)\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
       "(Intercept)   0.181532  0.0444716        4.08    <1e-04\n",
       "X1            6.50038   0.00092852    7000.80    <1e-99\n",
       "X2           -3.49986   0.000928611  -3768.92    <1e-99\n",
       "X3            0.999712  0.000927237   1078.16    <1e-99\n",
       "X4            4.99923   0.000927316   5391.08    <1e-99\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(bm_mm)\n",
    "mj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ\u001b[1m         Method \u001b[0m‚îÇ\u001b[1m Runtime \u001b[0m‚îÇ\u001b[1m        Log-Like \u001b[0m‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ      My method ‚îÇ    0.09 ‚îÇ -2840058.786650 ‚îÇ\n",
      "‚îÇ           lme4 ‚îÇ   92.47 ‚îÇ -2840058.786650 ‚îÇ\n",
      "‚îÇ MixedModels.jl ‚îÇ    0.61 ‚îÇ -2840058.786743 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "pretty_table(\n",
    "    hcat(method, runtime, loglike),\n",
    "    header = [\"Method\", \"Runtime\", \"Log-Like\"],\n",
    "    formatters = (ft_printf(\"%5.2f\", 2), ft_printf(\"%8.6f\", 3))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Be proud of yourself\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analysis on complex longitudinal data sets with millions of records. And you beat current software by XXX fold."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
